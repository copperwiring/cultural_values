{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_questions_file = '../categorized_questions.jsonl'\n",
    "\n",
    "# read categorized questions\n",
    "categorized_questions = []\n",
    "with open(categorized_questions_file, 'r') as f:\n",
    "    for line in f:\n",
    "        categorized_questions.append(json.loads(line))\n",
    "\n",
    "# List of all questions\n",
    "categorized_questions_list = [list(q.values())[0] for q in categorized_questions]\n",
    "\n",
    "# create a dictionary to map questions to their categories\n",
    "question_to_category = {q['Question']: q['Category'] for q in categorized_questions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of unique categories: 15\n",
      "['A. Social values and attitudes', 'B. Religion and spirituality', 'C. Science and technology', 'D. Politics and policy', 'E. Demographics', 'G. International affairs', 'I. Gender and LGBTQ', 'J. News habits and media', 'K. Immigration and migration', 'L. Family and relationships', 'M. Race and ethnicity', 'N. Economy and work', 'O. Regions and countries', 'P. Methodological research', 'Q. Security']\n"
     ]
    }
   ],
   "source": [
    "# all unique categories in question_to_category\n",
    "unique_categories = sorted(set(question_to_category.values()))\n",
    "print(f\"Lenght of unique categories: {len(unique_categories)}\")\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load of the CSV Data\n",
    "- CSV Data: CSV Files for Dollar Street dataset\n",
    "- No. of countries are: __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ds_wvs_metadata_llava-v1.5-13b_True_results.csv', 'ds_wvs_metadata_llava-v1.5-13b_False_results.csv', 'ds_wvs_metadata_llava-v1.6-34b_True_results.csv', 'ds_wvs_metadata_llava-v1.6-34b_False_results.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "import ast\n",
    "\n",
    "# List all files in the directory\n",
    "directory = \"/home/vsl333/cultural_values/notebooks/outputs\"\n",
    "\n",
    "# True => Country was in the prompt\n",
    "# False => Country was not in the prompt, only image was used\n",
    "# country_file, image_file = ['ds_wvs_metadata_llava-v1.5-13b_True_results.csv', 'ds_wvs_metadata_llava-v1.5-13b_False_results.csv',\n",
    "#                             'ds_wvs_metadata_llava-v1.6-34b_True_results.csv', 'ds_wvs_metadata_llava-v1.6-34b_False_results.csv']\n",
    "country_image_file_list = ['ds_wvs_metadata_llava-v1.5-13b_True_results.csv', 'ds_wvs_metadata_llava-v1.5-13b_False_results.csv',\n",
    "                            'ds_wvs_metadata_llava-v1.6-34b_True_results.csv', 'ds_wvs_metadata_llava-v1.6-34b_False_results.csv']\n",
    "print(country_image_file_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load one csv file to understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', 80)\n",
    "# data_country = pd.read_csv(os.path.join(directory, country_file))\n",
    "# data_country = data_country.reset_index(drop=True)\n",
    "\n",
    "# data_country.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_image = pd.read_csv(os.path.join(directory, image_file))\n",
    "# data_image = data_image.reset_index(drop=True)\n",
    "# data_image.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find common questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # give all unique values in question_text column\n",
    "# questions_country = data_country.question_text.unique()\n",
    "# questions_image = data_image.question_text.unique()\n",
    "\n",
    "# # check  questions which are not same?\n",
    "# uncommom_questions = [q for q in questions_country if q not in questions_country]\n",
    "# print(f\"Questions which are not common in both files: {uncommom_questions}\")\n",
    "\n",
    "# common_questions = [q for q in questions_country if q in questions_image]\n",
    "# print(f\"Common questions length: {len(common_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find unique countries in both country level nad image level data\n",
    "- check if both have same countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Country Level: {data_country['country'].unique()} \\n \\n Image Level: {data_image['country'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a combine dataframe for both country and image level data\n",
    "-  Image and text dataframe will be concatenated\n",
    "- 'Image' column will be True for Image level data and False for Country level data\n",
    "- 'jsd' and 'similarity' columns have Jensen Shannon Divergence and Similarity (1-JSD) values for each question\n",
    "- 'coutry_mean_similarity' and 'country_mean_jsd' columns have mean similarity and JSD values for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ds_wvs_metadata_llava-v1.5-13b_True_results.csv, has_image: False, modelsize: 13b\n",
      "Processing file: ds_wvs_metadata_llava-v1.5-13b_False_results.csv, has_image: True, modelsize: 13b\n",
      "Processing file: ds_wvs_metadata_llava-v1.6-34b_True_results.csv, has_image: False, modelsize: 34b\n",
      "Processing file: ds_wvs_metadata_llava-v1.6-34b_False_results.csv, has_image: True, modelsize: 34b\n",
      "Pre filtered shape: (61040, 24)\n",
      "Post filtered shape: (60728, 24)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# loop over data_image and data_country\n",
    "for idx, each_file in enumerate(country_image_file_list):\n",
    "    \n",
    "    # 'True' => Country was in the prompt, 'False' => Country was not in the prompt, only image was used\n",
    "    has_image = 'True' if 'False' in each_file else 'False' if 'True' in each_file else print(\"Missing: Neither 'True' nor 'False' is present in the file name\")\n",
    "    modelsize = '13b' if '13b' in each_file else '34b' if '34b' in each_file else print(\"Check the file name!!\")\n",
    "    \n",
    "    print(f\"Processing file: {each_file}, has_image: {has_image}, modelsize: {modelsize}\")\n",
    "    \n",
    "    each_data = pd.read_csv(os.path.join(directory, each_file))\n",
    "    data = each_data\n",
    "\n",
    "    # Example gt and pred (list of lists)\n",
    "    gt = [ast.literal_eval(x) for x in data['selection_answers'].tolist()] # there are prob distrbutions of human answers\n",
    "    pred = [ast.literal_eval(x) for x in data['prob_percent_values'].tolist()] # there are prob distrbutions of model answers\n",
    "\n",
    "    # Original DataFrame, retaining all columns from `data`\n",
    "    df = data.copy()\n",
    "\n",
    "    # Keep track of matching indices\n",
    "    matching_indices = [i for i, (g, p) in enumerate(zip(gt, pred)) if len(g) == len(p)]\n",
    "\n",
    "    # Filter rows where len(g) == len(p)\n",
    "    filtered_gt_pred = [(g, p) for g, p in zip(gt, pred) if len(g) == len(p)]\n",
    "\n",
    "    # If there are any matching rows\n",
    "    if filtered_gt_pred:\n",
    "        gt_filtered, pred_filtered = zip(*filtered_gt_pred)\n",
    "\n",
    "        # Calculate JSD\n",
    "        jsd = [distance.jensenshannon(g, p) for g, p in zip(gt_filtered, pred_filtered)]\n",
    "        similarity = [1 - value for value in jsd]\n",
    "\n",
    "        # Add JSD and similarity values back to the DataFrame\n",
    "        df.loc[matching_indices, 'jsd'] = jsd\n",
    "        df.loc[matching_indices, 'similarity'] = similarity\n",
    "    else:\n",
    "        df['jsd'] = None  # or handle the case accordingly\n",
    "        df['similarity'] = None\n",
    "\n",
    "    # Set JSD and similarity to NaN or a placeholder for rows that were filtered out\n",
    "    df['jsd'] = pd.to_numeric(df['jsd'], errors='coerce')\n",
    "    df['similarity'] = pd.to_numeric(df['similarity'], errors='coerce')\n",
    "    \n",
    "    df['Image'] = 'False' if has_image == 'False' else 'True' if has_image == 'True' else print(\"Something missing! Image is not True or False\")\n",
    "    df['model_size'] = modelsize\n",
    "\n",
    "    #\n",
    "    # Calculate mean of jsd and similarity per country per 'Image' column and add new col 'mean_jsd' and 'mean_similarity'\n",
    "    df['country_mean_jsd'] = df.groupby(['country', 'Image'])['jsd'].transform('mean')\n",
    "    df['coutry_mean_similarity'] = df.groupby(['country', 'Image'])['similarity'].transform('mean')\n",
    "\n",
    "    # Append results to list\n",
    "    results.append(df)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_results = pd.concat(results)\n",
    "print(f\"Pre filtered shape: {final_results.shape}\")\n",
    "\n",
    "# drop any rows with NaN values\n",
    "final_results = final_results.dropna()\n",
    "print(f\"Post filtered shape: {final_results.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image  model_size\n",
      "True   13b           7628\n",
      "False  13b           1537\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>sum_prob_percent_sorted</th>\n",
       "      <th>jsd</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <th>model_size</th>\n",
       "      <th>image_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">False</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">13b</th>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be794cf0b3a0f3f345b34.jpg</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be799cf0b3a0f3f345bcc.jpg</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7a5cf0b3a0f3f345d32.jpg</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b2cf0b3a0f3f345eb6.jpg</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b7cf0b3a0f3f345f40.jpg</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">13b</th>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/United States/5f19d7b753ddc6638484f7d0.jpg</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4becfbcf0b3a0f3f34ece6.jpg</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed0fcf0b3a0f3f34eee2.jpg</th>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed11cf0b3a0f3f34ef28.jpg</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bf4b0cf0b3a0f3f35c062.jpg</th>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                prompt  \\\n",
       "Image model_size image_path                                                                                                              \n",
       "False 13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be794cf0b3a0f3f345b34.jpg         22   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be799cf0b3a0f3f345bcc.jpg         21   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7a5cf0b3a0f3f345d32.jpg         18   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b2cf0b3a0f3f345eb6.jpg         20   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b7cf0b3a0f3f345f40.jpg         24   \n",
       "...                                                                                                                                ...   \n",
       "True  13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/United States/5f19d7b753ddc6638484f7d0.jpg     109   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4becfbcf0b3a0f3f34ece6.jpg           128   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed0fcf0b3a0f3f34eee2.jpg           119   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed11cf0b3a0f3f34ef28.jpg           117   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bf4b0cf0b3a0f3f35c062.jpg           121   \n",
       "\n",
       "                                                                                                                                sum_prob_percent_sorted  \\\n",
       "Image model_size image_path                                                                                                                               \n",
       "False 13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be794cf0b3a0f3f345b34.jpg                          22   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be799cf0b3a0f3f345bcc.jpg                          21   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7a5cf0b3a0f3f345d32.jpg                          18   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b2cf0b3a0f3f345eb6.jpg                          20   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b7cf0b3a0f3f345f40.jpg                          24   \n",
       "...                                                                                                                                                 ...   \n",
       "True  13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/United States/5f19d7b753ddc6638484f7d0.jpg                      109   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4becfbcf0b3a0f3f34ece6.jpg                            128   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed0fcf0b3a0f3f34eee2.jpg                            119   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed11cf0b3a0f3f34ef28.jpg                            117   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bf4b0cf0b3a0f3f35c062.jpg                            121   \n",
       "\n",
       "                                                                                                                                jsd  \\\n",
       "Image model_size image_path                                                                                                           \n",
       "False 13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be794cf0b3a0f3f345b34.jpg      22   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be799cf0b3a0f3f345bcc.jpg      21   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7a5cf0b3a0f3f345d32.jpg      18   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b2cf0b3a0f3f345eb6.jpg      20   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b7cf0b3a0f3f345f40.jpg      24   \n",
       "...                                                                                                                             ...   \n",
       "True  13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/United States/5f19d7b753ddc6638484f7d0.jpg  109   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4becfbcf0b3a0f3f34ece6.jpg        128   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed0fcf0b3a0f3f34eee2.jpg        119   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed11cf0b3a0f3f34ef28.jpg        117   \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bf4b0cf0b3a0f3f35c062.jpg        121   \n",
       "\n",
       "                                                                                                                                similarity  \n",
       "Image model_size image_path                                                                                                                 \n",
       "False 13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be794cf0b3a0f3f345b34.jpg             22  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be799cf0b3a0f3f345bcc.jpg             21  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7a5cf0b3a0f3f345d32.jpg             18  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b2cf0b3a0f3f345eb6.jpg             20  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Bangladesh/5d4be7b7cf0b3a0f3f345f40.jpg             24  \n",
       "...                                                                                                                                    ...  \n",
       "True  13b        /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/United States/5f19d7b753ddc6638484f7d0.jpg         109  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4becfbcf0b3a0f3f34ece6.jpg               128  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed0fcf0b3a0f3f34eee2.jpg               119  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bed11cf0b3a0f3f34ef28.jpg               117  \n",
       "                 /home/vsl333/cultural_values/datasets/dollarstreet_accurate_images/Vietnam/5d4bf4b0cf0b3a0f3f35c062.jpg               121  \n",
       "\n",
       "[156 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all rows in final_result where sum_prob_percent_sorted < 99\n",
    "mnp = final_results[final_results['sum_prob_percent_sorted'] < 99][['image_path', 'prompt', 'sum_prob_percent_sorted', 'Image', 'model_size','jsd', 'similarity']]\n",
    "print(mnp[['Image', 'model_size']].value_counts())\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "mnp.groupby(['Image', 'model_size','image_path']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter rows where sum_prob_percent_sorted <99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the total data: (60728, 24)\n",
      "Size of the filtered data: (51563, 24)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of the total data: {final_results.shape}\")\n",
    "# Filter rows where sum_prob_percent_sorted <99\n",
    "filtered_final_result = final_results[final_results['sum_prob_percent_sorted'] > 99]\n",
    "print(f\"Size of the filtered data: {filtered_final_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 'question_topic' to both dataframes\n",
    "- 'question_topic' is the column which has each question mapped to a broad topic\n",
    "- Broad topics are: {'B. Religion and spirituality', 'E. Demographics', 'A. Social values and attitudes', 'D. Politics and policy', 'O. Regions and countries', 'J. News habits and media', 'G. International affairs', 'M. Race and ethnicity', 'N. Economy and work', 'P. Methodological research', 'C. Science and technology', 'K. Immigration and migration', 'L. Family and relationships', 'Q. Security', 'I. Gender and LGBTQ'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_id', 'image_path', 'country', 'image_code', 'income',\n",
       "       'question_text', 'country_prompt', 'generic_prompt', 'option_labels',\n",
       "       'full_options', 'prompt', 'options', 'top10_token_prob',\n",
       "       'prob_percent_sorted', 'sum_prob_percent_sorted', 'prob_percent_keys',\n",
       "       'prob_percent_values', 'selection_answers', 'jsd', 'similarity',\n",
       "       'Image', 'model_size', 'country_mean_jsd', 'coutry_mean_similarity',\n",
       "       'question_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_final_result['question_topic'] = filtered_final_result['question_text'].map(question_to_category)\n",
    "filtered_final_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "img_id                     0\n",
       "image_path                 0\n",
       "country                    0\n",
       "image_code                 0\n",
       "income                     0\n",
       "question_text              0\n",
       "country_prompt             0\n",
       "generic_prompt             0\n",
       "option_labels              0\n",
       "full_options               0\n",
       "prompt                     0\n",
       "options                    0\n",
       "top10_token_prob           0\n",
       "prob_percent_sorted        0\n",
       "sum_prob_percent_sorted    0\n",
       "prob_percent_keys          0\n",
       "prob_percent_values        0\n",
       "selection_answers          0\n",
       "jsd                        0\n",
       "similarity                 0\n",
       "Image                      0\n",
       "model_size                 0\n",
       "country_mean_jsd           0\n",
       "coutry_mean_similarity     0\n",
       "question_topic             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows where nan values are present\n",
    "filtered_final_result.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bangladesh', 'Brazil', 'China', 'France', 'Iran', 'Italy',\n",
       "       'Kenya', 'Mexico', 'Nigeria', 'Pakistan', 'South Korea', 'Spain',\n",
       "       'United States', 'Vietnam'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_final_result['country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each question topic/model, calculate the mean similarity, JSD values, MD Sim for each country\n",
    "- column names will be 'question_topic_mean_jsd' and 'question_topic_mean_similarity'\n",
    "- For marginal distribution similarity, column name will be 'md_topic_pred', 'md_topic_gt', 'md_sim_topic', 'md_sim_overall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un_rich_countries = [\"United States\", \"Russia\", \"Romania\", \"France\", \"Spain\", \"Italy\", \"South Korea\", ]\n",
    "# un_medium_countries = [\"Mexico\", \"Mongolia\", \"Brazil\",\"Colombia\", \"Iran\", \"Indonesia\", \"Philippines\", \"China\", ]\n",
    "# un_poor_countries = [\"Ethiopia\", \"Nigeria\", \"Egypt\", \"Kenya\", \"Vietnam\", \"Bangladesh\", \"Pakistan\"]\n",
    "# un_country_list = un_rich_countries + un_medium_countries + un_poor_countries\n",
    "\n",
    "ds_rich_countries = [\"United States\"]\n",
    "ds_medium_countries = [\"Brazil\", \"China\", \"South Africa\" ]\n",
    "ds_poor_countries = [\"Nigeria\", \"Bangladesh\", \"Pakistan\"]\n",
    "\n",
    "country_list = ds_rich_countries + ds_medium_countries + ds_poor_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Marginal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Func for marginal distribution calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_distributions(distributions):\n",
    "    # Ensure all distributions are lists (not strings)\n",
    "    distributions = [ast.literal_eval(dist) if isinstance(dist, str) else dist for dist in distributions]\n",
    "    \n",
    "    # Ensure all distributions are valid lists of numbers\n",
    "    valid_distributions = [np.array(dist, dtype=float) for dist in distributions if isinstance(dist, list)]\n",
    "\n",
    "    # Calculate the average distribution\n",
    "    average_dist =  np.mean(np.array(valid_distributions), axis=0).tolist()\n",
    "    \n",
    "    return average_dist\n",
    "\n",
    "# General function to calculate marginal distribution and merge it back into the DataFrame\n",
    "def calculate_and_merge_marginal_distribution(df, groupby_columns, target_column, new_column_name):\n",
    "    \"\"\"\n",
    "    Generalized function to calculate marginal distribution, reset index, and merge back to the original DataFrame.\n",
    "    \"\"\"\n",
    "    marginal_df = (\n",
    "        df.groupby(groupby_columns)[target_column]\n",
    "        .apply(average_distributions)\n",
    "        .reset_index(name=new_column_name)\n",
    "    )\n",
    "    return df.merge(marginal_df, on=groupby_columns, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Func to compute jsd and 1-jsd for the marginalized distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# Function to calculate Jensen-Shannon Divergence (JSD)\n",
    "def calculate_jsd(p, q):\n",
    "    if len(p) == 0 or len(q) == 0:  # Check for empty distributions\n",
    "        return None  # or return a specific value indicating no valid distributions\n",
    "    return jensenshannon(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to compute jsd and similarity (1-jsd) for \n",
    "- each question topic\n",
    "- marginal distribution distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_id', 'image_path', 'country', 'image_code', 'income',\n",
       "       'question_text', 'country_prompt', 'generic_prompt', 'option_labels',\n",
       "       'full_options', 'prompt', 'options', 'top10_token_prob',\n",
       "       'prob_percent_sorted', 'sum_prob_percent_sorted', 'prob_percent_keys',\n",
       "       'prob_percent_values', 'selection_answers', 'jsd', 'similarity',\n",
       "       'Image', 'model_size', 'country_mean_jsd', 'coutry_mean_similarity',\n",
       "       'question_topic', 'question_topic_mean_jsd',\n",
       "       'question_topic_mean_similarity',\n",
       "       'question_topic_country_mean_similarity', 'md_topic_pred',\n",
       "       'md_topic_gt', 'md_all_pred', 'md_all_gt', 'md_jsd_topic',\n",
       "       'md_sim_topic', 'md_jsd_overall', 'md_sim_overall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each question_topic, calculate mean of jsd and similarity per country and save as different df \n",
    "# save all dfs in a dictionary\n",
    "\n",
    "# Calculate mean of 'jsd' per 'question_topic', Image'\n",
    "filtered_final_result['question_topic_mean_jsd'] = filtered_final_result.groupby(['question_topic', 'Image', 'model_size'])['jsd'].transform('mean')\n",
    "# Calculate mean of 'similarity' per 'question_topic','Image'\n",
    "filtered_final_result['question_topic_mean_similarity'] = filtered_final_result.groupby(['question_topic', 'Image', 'model_size'])['similarity'].transform('mean')\n",
    "# Calculate mean of 'question_topic_mean_similarity' per country\n",
    "filtered_final_result['question_topic_country_mean_similarity'] = filtered_final_result.groupby(['question_topic', 'country', 'Image', 'model_size'])['similarity'].transform('mean')\n",
    "\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_topic', 'question_text', 'Image', 'model_size'], 'prob_percent_values', 'md_topic_pred'\n",
    ")\n",
    "\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_topic', 'question_text', 'Image', 'model_size'], 'selection_answers', 'md_topic_gt'\n",
    ")\n",
    "\n",
    "# Step 3 and 4: Calculate marginalized model prediction and ground truth across all images per question only\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_text', 'Image', 'model_size'], 'prob_percent_values', 'md_all_pred'\n",
    ")\n",
    "\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_text', 'Image', 'model_size'], 'selection_answers', 'md_all_gt'\n",
    ")\n",
    "\n",
    "# Calculate JSD for each question topic\n",
    "filtered_final_result['md_jsd_topic'] = filtered_final_result.apply(\n",
    "    lambda row: calculate_jsd(row['md_topic_pred'], row['md_topic_gt']), axis=1\n",
    ")\n",
    "filtered_final_result['md_sim_topic'] = 1 - filtered_final_result['md_jsd_topic']\n",
    "\n",
    "# Calculate JSD for overall predictions and ground truth\n",
    "filtered_final_result['md_jsd_overall'] = filtered_final_result.apply(\n",
    "    lambda row: calculate_jsd(row['md_all_pred'], row['md_all_gt']), axis=1\n",
    ")\n",
    "filtered_final_result['md_sim_overall'] = 1 - filtered_final_result['md_jsd_overall']\n",
    "\n",
    "# print column names\n",
    "filtered_final_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51563, 36)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_final_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final df and (question)topic level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed! Deleted topic_csv directory\n",
      "Question Topic Level Data will be saved at: topic_csv\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "question_topic_ouput_dir = 'topic_csv'\n",
    "\n",
    "# delete directory if already exist. Include subdirectories\n",
    "if os.path.exists(question_topic_ouput_dir):\n",
    "    shutil.rmtree(question_topic_ouput_dir)\n",
    "    print(f\"Existed! Deleted {question_topic_ouput_dir} directory\")\n",
    "\n",
    "# create directory\n",
    "os.makedirs(question_topic_ouput_dir)\n",
    "print(f\"Question Topic Level Data will be saved at: {question_topic_ouput_dir}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/all_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/A. Social values and attitudes.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:00<00:03,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/B. Religion and spirituality.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:01<00:04,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/C. Science and technology.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:03<00:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/D. Politics and policy.csv\n",
      "Saved data: topic_csv/E. Demographics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:03<00:05,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/G. International affairs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:04<00:03,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/I. Gender and LGBTQ.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:04<00:03,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/J. News habits and media.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:04<00:02,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/K. Immigration and migration.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:06<00:02,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/L. Family and relationships.csv\n",
      "Saved data: topic_csv/M. Race and ethnicity.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [00:07<00:02,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/N. Economy and work.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [00:08<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/O. Regions and countries.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [00:13<00:02,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/P. Methodological research.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:14<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/Q. Security.csv\n",
      "Question Topic Level Data saved at: topic_csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_final_result.to_csv(f\"{question_topic_ouput_dir}/all_results.csv\", index=False)\n",
    "print(f\"Saved data: {question_topic_ouput_dir}/all_results.csv\")\n",
    "\n",
    "# Create separate DataFrames per question topic and save them\n",
    "df_category_similarity = {}\n",
    "question_topics = sorted(filtered_final_result['question_topic'].unique())\n",
    "\n",
    "for topic in tqdm(question_topics):\n",
    "    df_category = filtered_final_result[filtered_final_result['question_topic'] == topic]\n",
    "    df_category_similarity[topic] = df_category\n",
    "    df_category.to_csv(f\"{question_topic_ouput_dir}/{topic}.csv\", index=False)\n",
    "    print(f\"Saved data: {question_topic_ouput_dir}/{topic}.csv\")\n",
    "\n",
    "print(f\"Question Topic Level Data saved at: {question_topic_ouput_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A. Social values and attitudes', 'B. Religion and spirituality', 'C. Science and technology', 'D. Politics and policy', 'E. Demographics', 'G. International affairs', 'I. Gender and LGBTQ', 'J. News habits and media', 'K. Immigration and migration', 'L. Family and relationships', 'M. Race and ethnicity', 'N. Economy and work', 'O. Regions and countries', 'P. Methodological research', 'Q. Security'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_category_similarity.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3735556707.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[48], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    so that notebook breaks here if you run from top\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "so that notebook breaks here if you run from top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Compute Marginal Distribution -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Func for marginal distribution calculation -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_distributions(distributions):\n",
    "#     # Ensure all distributions are lists (not strings)\n",
    "#     distributions = [ast.literal_eval(dist) if isinstance(dist, str) else dist for dist in distributions]\n",
    "    \n",
    "#     # Ensure all distributions are valid lists of numbers\n",
    "#     valid_distributions = [np.array(dist, dtype=float) for dist in distributions if isinstance(dist, list)]\n",
    "\n",
    "#     # Calculate the average distribution\n",
    "#     average_dist =  np.mean(np.array(valid_distributions), axis=0).tolist()\n",
    "    \n",
    "#     return average_dist\n",
    "\n",
    "# # General function to calculate marginal distribution and merge it back into the DataFrame\n",
    "# def calculate_and_merge_marginal_distribution(df, groupby_columns, target_column, new_column_name):\n",
    "#     \"\"\"\n",
    "#     Generalized function to calculate marginal distribution, reset index, and merge back to the original DataFrame.\n",
    "#     \"\"\"\n",
    "#     marginal_df = (\n",
    "#         df.groupby(groupby_columns)[target_column]\n",
    "#         .apply(average_distributions)\n",
    "#         .reset_index(name=new_column_name)\n",
    "#     )\n",
    "#     return df.merge(marginal_df, on=groupby_columns, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Func to compute jsd and 1-jsd for the marginalized distributions -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# # Function to calculate Jensen-Shannon Divergence (JSD)\n",
    "# def calculate_jsd(p, q):\n",
    "#     if len(p) == 0 or len(q) == 0:  # Check for empty distributions\n",
    "#         return None  # or return a specific value indicating no valid distributions\n",
    "#     return jensenshannon(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Code to compute jsd and similarity (1-jsd) for the joint distribution -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1 and 2: Calculate marginalized model prediction and ground truth per topic and question\n",
    "# final_result = calculate_and_merge_marginal_distribution(\n",
    "#     final_result, ['question_topic', 'question_text'], 'prob_percent_values', 'md_topic_pred'\n",
    "# )\n",
    "\n",
    "# final_result = calculate_and_merge_marginal_distribution(\n",
    "#     final_result, ['question_topic', 'question_text'], 'selection_answers', 'md_topic_gt'\n",
    "# )\n",
    "\n",
    "# # Step 3 and 4: Calculate marginalized model prediction and ground truth across all images per question only\n",
    "# final_result = calculate_and_merge_marginal_distribution(\n",
    "#     final_result, ['question_text'], 'prob_percent_values', 'md_all_pred'\n",
    "# )\n",
    "\n",
    "# final_result = calculate_and_merge_marginal_distribution(\n",
    "#     final_result, ['question_text'], 'selection_answers', 'md_all_gt'\n",
    "# )\n",
    "\n",
    "# # Calculate JSD for each question topic\n",
    "# final_result['md_jsd_topic'] = final_result.apply(\n",
    "#     lambda row: calculate_jsd(row['md_topic_pred'], row['md_topic_gt']), axis=1\n",
    "# )\n",
    "# final_result['md_sim_topic'] = 1 - final_result['md_jsd_topic']\n",
    "\n",
    "# # Calculate JSD for overall predictions and ground truth\n",
    "# final_result['md_jsd_overall'] = final_result.apply(\n",
    "#     lambda row: calculate_jsd(row['md_all_pred'], row['md_all_gt']), axis=1\n",
    "# )\n",
    "# final_result['md_sim_overall'] = 1 - final_result['md_jsd_overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Question Topic level similarity and JSD values for each country\n",
    "- This is per country\n",
    "- Note that all images are for people of same demographic group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from matplotlib.transforms import blended_transform_factory\n",
    "\n",
    "\n",
    "\n",
    "# # Assuming df_category_similarity is a dictionary with dataframes per topic\n",
    "# # and 'country_list' is defined as a list of country names in desired order\n",
    "\n",
    "# # Directory to save individual figures\n",
    "# individual_figures_dir = 'plots/individual_topic_figures'\n",
    "# if os.path.exists(individual_figures_dir):\n",
    "#     shutil.rmtree(individual_figures_dir)\n",
    "#     print(f\"Existed! Deleted {individual_figures_dir} directory\")\n",
    "# os.makedirs(individual_figures_dir, exist_ok=True)\n",
    "\n",
    "# # List of unique question topics\n",
    "# question_topics = sorted(final_result['question_topic'].unique())\n",
    "\n",
    "# # Prepare for plotting\n",
    "# n_cols = 3  # Number of subplots per row\n",
    "# n_rows = int(np.ceil(len(question_topics) / n_cols))\n",
    "\n",
    "# fig_width = 6 * n_cols\n",
    "# fig_height = 4 * n_rows\n",
    "# fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height))\n",
    "# axs = axs.flatten()  # Flatten the array of axes\n",
    "\n",
    "\n",
    "# for idx, topic in enumerate(question_topics):\n",
    "#     df_category = df_category_similarity[topic].copy()\n",
    "    \n",
    "#     # Convert 'Image' column to boolean\n",
    "#     df_category['Image'] = df_category['Image'].map({'False': False, 'True': True})\n",
    "    \n",
    "#     # Calculate mean 'question_topic_mean_similarity' per country and Image scenario\n",
    "#     df_mean = df_category.groupby(['country', 'Image'])['question_topic_mean_similarity'].mean().reset_index()\n",
    "    \n",
    "#     # Pivot the data to have Image scenarios as columns\n",
    "#     df_pivot = df_mean.pivot(index='country', columns='Image', values='question_topic_mean_similarity').reset_index()\n",
    "    \n",
    "#     # Rename columns using boolean keys\n",
    "#     df_pivot = df_pivot.rename(columns={False: 'Text Similarity', True: 'Image Similarity'})\n",
    "    \n",
    "#     # Ensure both 'Text Similarity' and 'Image Similarity' columns exist\n",
    "#     if 'Text Similarity' not in df_pivot.columns:\n",
    "#         df_pivot['Text Similarity'] = np.nan\n",
    "#     if 'Image Similarity' not in df_pivot.columns:\n",
    "#         df_pivot['Image Similarity'] = np.nan\n",
    "    \n",
    "#     # Drop countries that have missing data in either scenario\n",
    "#     df_pivot = df_pivot.dropna()\n",
    "    \n",
    "#     # Sort countries based on 'country_list'\n",
    "#     df_pivot['country'] = pd.Categorical(df_pivot['country'], categories=country_list, ordered=True)\n",
    "\n",
    "#     # Drop countries that have missing data in either scenario\n",
    "#     df_pivot = df_pivot.dropna()\n",
    "    \n",
    "#     df_pivot = df_pivot.sort_values('country')\n",
    "    \n",
    "#     # Data for plotting\n",
    "#     countries = df_pivot['country']\n",
    "#     text_similarities = df_pivot['Text Similarity']\n",
    "#     image_similarities = df_pivot['Image Similarity']\n",
    "    \n",
    "#     x = np.arange(len(countries))  # Label locations\n",
    "#     width = 0.35  # Width of the bars\n",
    "    \n",
    "#     ax = axs[idx]\n",
    "    \n",
    "#     # Plot bars on the subplot\n",
    "#     ax.bar(x - width/2, text_similarities, width, label= 'Country Prompt- No Images')\n",
    "#     ax.bar(x + width/2, image_similarities, width, label='No Country Prompt- Only Images')\n",
    "    \n",
    "#     # Compute the mean similarity for the topic using text-level data only\n",
    "#     text_mean = df_pivot['Text Similarity'].mean()\n",
    "    \n",
    "#     # Plot horizontal red dashed line at text_mean\n",
    "#     ax.axhline(text_mean, color='red', linestyle='--')\n",
    "\n",
    "#     # Create a blended transformation for the subplot\n",
    "#     transform = blended_transform_factory(ax.transAxes, ax.transData)\n",
    "    \n",
    "#     # Annotate the mean value on the plot\n",
    "#     ax.text(0.01, text_mean, f'{text_mean:.2f}', color='black', ha='left', va='bottom', transform=ax.get_yaxis_transform())\n",
    "    \n",
    "#     # Remove prefix (e.g., 'A.', 'B.', etc.) from topic name\n",
    "#     topic_title = topic.split('.', 1)[-1].strip()\n",
    "    \n",
    "#     # Add labels, title, and custom x-axis tick labels\n",
    "#     ax.set_ylabel('Mean Similarity')\n",
    "#     ax.set_title(f'{topic_title}')\n",
    "#     ax.set_xticks(x)\n",
    "#     ax.set_xticklabels(countries, rotation=90)\n",
    "#     ax.tick_params(axis='x', which='major', labelsize=8)\n",
    "    \n",
    "#     # Create individual figure for the topic\n",
    "#     fig_individual, ax_individual = plt.subplots(figsize=(8, 4))\n",
    "    \n",
    "#     # Plot bars on the individual figure\n",
    "#     ax_individual.bar(x - width/2, text_similarities, width, label= 'Country Prompt- No Images')\n",
    "#     ax_individual.bar(x + width/2, image_similarities, width, label='No Country Prompt- Only Images')\n",
    "    \n",
    "#     # Plot horizontal red dashed line at text_mean\n",
    "#     ax_individual.axhline(text_mean, color='red', linestyle='--')\n",
    "    \n",
    "#     # Annotate the mean value on the individual plot\n",
    "#     ax_individual.text(0.01, text_mean, f'{text_mean:.2f}', color='black', ha='left', va='bottom', transform=ax_individual.get_yaxis_transform())\n",
    "    \n",
    "#     # Add labels, title, and custom x-axis tick labels\n",
    "#     ax_individual.set_ylabel('Mean Similarity')\n",
    "#     ax_individual.set_title(f'{topic_title}')\n",
    "#     ax_individual.set_xticks(x)\n",
    "#     ax_individual.set_xticklabels(countries, rotation=90)\n",
    "#     ax_individual.tick_params(axis='x', which='major', labelsize=8)\n",
    "    \n",
    "#     # Add legend to individual figure, located in the upper right corner outside the plot area\n",
    "#     ax_individual.legend(loc='upper left', bbox_to_anchor=(1, 1), frameon=False)\n",
    "    \n",
    "#     # Adjust layout to make room for the legend\n",
    "#     fig_individual.tight_layout(rect=[0, 0, 0.8, 1])  # Leave space on the right for the legend\n",
    "    \n",
    "#     # Save individual figure\n",
    "#     fig_individual.savefig(os.path.join(individual_figures_dir, f'{topic_title}.png'), bbox_inches='tight')\n",
    "#     plt.close(fig_individual)  # Close the figure to free memory\n",
    "    \n",
    "# # Remove empty subplots if any\n",
    "# for idx in range(len(question_topics), n_rows * n_cols):\n",
    "#     fig.delaxes(axs[idx])\n",
    "\n",
    "# # Adjust layout to make room for the legend\n",
    "# plt.tight_layout(rect=[0, 0, 0.85, 1])  # Leave space on the right\n",
    "\n",
    "# # Add a single legend on the right\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='upper right', bbox_to_anchor=(1.0, 0.5), frameon=False)\n",
    "# # Save the final figure with all subplots\n",
    "# fig.savefig(f'{individual_figures_dir}/final_similarity_plot.png', bbox_inches='tight')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Question Topic level similarity and JSD values for each economic strate \n",
    "- This is per low income, middle income and high income\n",
    "- Note that all images are for people of same demographic group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from matplotlib.transforms import blended_transform_factory\n",
    "\n",
    "# # # Define income groups\n",
    "# # rich_countries = [\"United States\", \"Russia\", \"Romania\", \"France\", \"Spain\", \"Italy\", \"South Korea\"]\n",
    "# # medium_countries = [\"Mexico\", \"Mongolia\", \"Brazil\", \"Colombia\", \"Iran\", \"Indonesia\", \"Philippines\", \"China\"]\n",
    "# # poor_countries = [\"Ethiopia\", \"Nigeria\", \"Egypt\", \"Kenya\", \"Vietnam\", \"Bangladesh\", \"Pakistan\"]\n",
    "\n",
    "# # Create mapping from country to income group\n",
    "# country_income_group = {}\n",
    "# for country in ds_rich_countries:\n",
    "#     country_income_group[country] = 'Rich'\n",
    "# for country in ds_medium_countries:\n",
    "#     country_income_group[country] = 'Medium'\n",
    "# for country in ds_poor_countries:\n",
    "#     country_income_group[country] = 'Poor'\n",
    "\n",
    "# # Directory to save individual figures\n",
    "# individual_figures_dir = 'ds_wvs/individual_topic_figures_income_groups'\n",
    "# if os.path.exists(individual_figures_dir):\n",
    "#     shutil.rmtree(individual_figures_dir)\n",
    "#     print(f\"Existed! Deleted {individual_figures_dir} directory\")\n",
    "# os.makedirs(individual_figures_dir, exist_ok=True)\n",
    "\n",
    "# # List of unique question topics\n",
    "# question_topics = sorted(final_result['question_topic'].unique())\n",
    "\n",
    "# # Prepare for plotting\n",
    "# n_cols = 3  # Number of subplots per row\n",
    "# n_rows = int(np.ceil(len(question_topics) / n_cols))\n",
    "\n",
    "# fig_width = 6 * n_cols\n",
    "# fig_height = 4 * n_rows\n",
    "# fig, axs = plt.subplots(n_rows, n_cols, figsize=(fig_width, fig_height))\n",
    "# axs = axs.flatten()  # Flatten the array of axes\n",
    "\n",
    "# for idx, topic in enumerate(question_topics):\n",
    "#     df_category = df_category_similarity[topic].copy()\n",
    "    \n",
    "#     # Map 'country' to 'IncomeGroup'\n",
    "#     df_category['IncomeGroup'] = df_category['country'].map(country_income_group)\n",
    "    \n",
    "#     # Remove rows with missing IncomeGroup\n",
    "#     df_category = df_category.dropna(subset=['IncomeGroup'])\n",
    "    \n",
    "#     # Convert 'Image' column to boolean\n",
    "#     df_category['Image'] = df_category['Image'].map({'False': False, 'True': True})\n",
    "    \n",
    "#     # Calculate mean 'question_topic_mean_similarity' per IncomeGroup and Image scenario\n",
    "#     df_mean = df_category.groupby(['IncomeGroup', 'Image'])['question_topic_mean_similarity'].mean().reset_index()\n",
    "    \n",
    "#     # Pivot the data to have Image scenarios as columns\n",
    "#     df_pivot = df_mean.pivot(index='IncomeGroup', columns='Image', values='question_topic_mean_similarity').reset_index()\n",
    "    \n",
    "#     # Rename columns using boolean keys\n",
    "#     df_pivot = df_pivot.rename(columns={False: 'Text Similarity', True: 'Image Similarity'})\n",
    "    \n",
    "#     # Ensure both 'Text Similarity' and 'Image Similarity' columns exist\n",
    "#     if 'Text Similarity' not in df_pivot.columns:\n",
    "#         df_pivot['Text Similarity'] = np.nan\n",
    "#     if 'Image Similarity' not in df_pivot.columns:\n",
    "#         df_pivot['Image Similarity'] = np.nan\n",
    "    \n",
    "#     # Drop IncomeGroups that have missing data in either scenario\n",
    "#     df_pivot = df_pivot.dropna()\n",
    "    \n",
    "#     # Sort IncomeGroups in the order Rich, Medium, Poor\n",
    "#     income_group_order = ['Rich', 'Medium', 'Poor']\n",
    "#     df_pivot['IncomeGroup'] = pd.Categorical(df_pivot['IncomeGroup'], categories=income_group_order, ordered=True)\n",
    "\n",
    "#     # Drop countries that have missing data in either scenario\n",
    "#     df_pivot = df_pivot.dropna()\n",
    "#     df_pivot = df_pivot.sort_values('IncomeGroup')\n",
    "    \n",
    "#     # Data for plotting\n",
    "#     income_groups = df_pivot['IncomeGroup']\n",
    "#     text_similarities = df_pivot['Text Similarity']\n",
    "#     image_similarities = df_pivot['Image Similarity']\n",
    "    \n",
    "#     x = np.arange(len(income_groups))  # Label locations\n",
    "#     width = 0.35  # Width of the bars\n",
    "    \n",
    "#     ax = axs[idx]\n",
    "    \n",
    "#     # Plot bars on the subplot\n",
    "#     ax.bar(x - width/2, text_similarities, width, label='Country Prompt- No Images')\n",
    "#     ax.bar(x + width/2, image_similarities, width, label='No Country Prompt- Only Images')\n",
    "    \n",
    "#     # Compute the mean similarity for the topic using text-level data only\n",
    "#     text_mean = df_pivot['Text Similarity'].mean()\n",
    "    \n",
    "#     # Plot horizontal red dashed line at text_mean\n",
    "#     ax.axhline(text_mean, color='red', linestyle='--')\n",
    "    \n",
    "#     # Create a blended transformation for the subplot\n",
    "#     transform = blended_transform_factory(ax.transAxes, ax.transData)\n",
    "    \n",
    "#     # Annotate the mean value on the plot (left end)\n",
    "#     ax.text(0.05, text_mean, f'{text_mean:.2f}', color='black',\n",
    "#             ha='left', va='bottom', transform=transform)\n",
    "    \n",
    "#     # Remove prefix (e.g., 'A.', 'B.', etc.) from topic name\n",
    "#     topic_title = topic.split('.', 1)[-1].strip()\n",
    "    \n",
    "#     # Add labels, title, and custom x-axis tick labels\n",
    "#     ax.set_ylabel('Mean Similarity')\n",
    "#     ax.set_title(f'{topic_title}')\n",
    "#     ax.set_xticks(x)\n",
    "#     ax.set_xticklabels(income_groups, rotation=0)\n",
    "#     ax.tick_params(axis='x', which='major', labelsize=8)\n",
    "    \n",
    "#     # Create individual figure for the topic\n",
    "#     fig_individual, ax_individual = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "#     # Plot bars on the individual figure\n",
    "#     ax_individual.bar(x - width/2, text_similarities, width, label='Country Prompt- No Images')\n",
    "#     ax_individual.bar(x + width/2, image_similarities, width, label='No Country Prompt- Only Images')\n",
    "    \n",
    "#     # Plot horizontal red dashed line at text_mean\n",
    "#     ax_individual.axhline(text_mean, color='red', linestyle='--')\n",
    "    \n",
    "#     # Annotate the mean value on the individual plot (left end)\n",
    "#     ax_individual.text(0.05, text_mean, f'{text_mean:.2f}', color='black',\n",
    "#                        ha='left', va='bottom', transform=ax_individual.get_yaxis_transform())\n",
    "    \n",
    "#     # Add labels, title, and custom x-axis tick labels\n",
    "#     ax_individual.set_ylabel('Mean Similarity')\n",
    "#     ax_individual.set_title(f'{topic_title}')\n",
    "#     ax_individual.set_xticks(x)\n",
    "#     ax_individual.set_xticklabels(income_groups, rotation=0)\n",
    "#     ax_individual.tick_params(axis='x', which='major', labelsize=8)\n",
    "    \n",
    "#     # Add legend to individual figure, located in the upper right corner outside the plot area\n",
    "#     ax_individual.legend(loc='upper left', bbox_to_anchor=(1, 1), frameon=False)\n",
    "    \n",
    "#     # Adjust layout to make room for the legend\n",
    "#     fig_individual.tight_layout(rect=[0, 0, 0.8, 1])  # Leave space on the right for the legend\n",
    "    \n",
    "#     # Save individual figure\n",
    "#     fig_individual.savefig(os.path.join(individual_figures_dir, f'{topic_title}.png'), bbox_inches='tight')\n",
    "#     plt.close(fig_individual)  # Close the figure to free memory\n",
    "\n",
    "# # Remove empty subplots if any\n",
    "# for idx in range(len(question_topics), n_rows * n_cols):\n",
    "#     fig.delaxes(axs[idx])\n",
    "\n",
    "# # Adjust layout to make room for the legend\n",
    "# plt.tight_layout(rect=[0, 0, 0.85, 1])  # Leave space on the right\n",
    "\n",
    "# # Add a single legend on the right\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# fig.legend(handles, labels, loc='center right')\n",
    "\n",
    "# # Save the final figure with all subplots\n",
    "# fig.savefig(f'{individual_figures_dir}/final_similarity_plot_income_groups.png', bbox_inches='tight')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer % change in similarity and JSD values for each question topic per income strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize a list to store the results\n",
    "# results = []\n",
    "\n",
    "# for topic in question_topics:\n",
    "#     df_category = df_category_similarity[topic].copy()\n",
    "    \n",
    "#     # Map 'country' to 'IncomeGroup'\n",
    "#     df_category['IncomeGroup'] = df_category['country'].map(country_income_group)\n",
    "    \n",
    "#     # Remove rows with missing IncomeGroup\n",
    "#     df_category = df_category.dropna(subset=['IncomeGroup'])\n",
    "    \n",
    "#     # Convert 'Image' column to boolean if not already\n",
    "#     if df_category['Image'].dtype == object:\n",
    "#         df_category['Image'] = df_category['Image'].map({'False': False, 'True': True})\n",
    "    \n",
    "#     # For each income group\n",
    "#     for income_group in ['Rich', 'Medium', 'Poor']:\n",
    "#         df_group = df_category[df_category['IncomeGroup'] == income_group]\n",
    "        \n",
    "#         # Mean 'Text Similarity' (Image == False)\n",
    "#         text_similarity_mean = df_group[df_group['Image'] == False]['question_topic_mean_similarity'].mean()\n",
    "        \n",
    "#         # Mean 'Image Similarity' (Image == True)\n",
    "#         image_similarity_mean = df_group[df_group['Image'] == True]['question_topic_mean_similarity'].mean()\n",
    "        \n",
    "#         # Compute percentage change from 'Text Similarity' to 'Image Similarity'\n",
    "#         if text_similarity_mean != 0 and not pd.isnull(text_similarity_mean):\n",
    "#             percentage_change = ((image_similarity_mean - text_similarity_mean) / text_similarity_mean) * 100\n",
    "#         else:\n",
    "#             percentage_change = None  # or np.nan\n",
    "        \n",
    "#         # Store the result\n",
    "#         results.append({\n",
    "#             'Topic': topic,\n",
    "#             'IncomeGroup': income_group,\n",
    "#             'Text Similarity IG Mean': text_similarity_mean,\n",
    "#             'Image Similarity IG Mean': image_similarity_mean,\n",
    "#             'Percentage Change': percentage_change\n",
    "#         })\n",
    "\n",
    "# # Convert results to DataFrame\n",
    "# df_variance_income_groups = pd.DataFrame(results)\n",
    "\n",
    "# df_variance_income_groups.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pivot the DataFrame to have topics as columns and similarity and percentage change as rows\n",
    "# df_pivot_topicwise = df_variance_income_groups.pivot(index='IncomeGroup', columns='Topic', values=['Text Similarity IG Mean', 'Image Similarity IG Mean', 'Percentage Change'])\n",
    "\n",
    "# # Flatten the MultiIndex columns\n",
    "# df_pivot_topicwise.columns = ['_'.join(col).strip() for col in df_pivot_topicwise.columns.values]\n",
    "\n",
    "# # Display the updated DataFrame with only % change columns\n",
    "# df_pivot_topicwise = df_pivot_topicwise.filter(like='Percentage Change', axis=1)\n",
    "# df_pivot_topicwise = df_pivot_topicwise.reindex(['Rich', 'Medium', 'Poor'])\n",
    "# df_pivot_topicwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each unique country, there is a column 'income'. It has tensor values e.g. tensor(174, dtype=torch.float64). I want to plot a historgram of these values for a) per country b) per income group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from torch import Tensor\n",
    "# import re\n",
    "\n",
    "# # Directory to save individual figures\n",
    "# individual_figures_income_dist = 'ds_wvs/individual_topic_figures_income_distribution'\n",
    "# if os.path.exists(individual_figures_income_dist):\n",
    "#     shutil.rmtree(individual_figures_income_dist)\n",
    "#     print(f\"Existed! Deleted {individual_figures_income_dist} directory\")\n",
    "# os.makedirs(individual_figures_income_dist, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: Extract numerical income values from tensors\n",
    "\n",
    "# def extract_income_value(tensor_value):\n",
    "#     if isinstance(tensor_value, str):\n",
    "#         # Use regex to extract the number inside 'tensor(...)'\n",
    "#         match = re.search(r'tensor\\(([\\d\\.\\-e]+)', tensor_value)\n",
    "#         if match:\n",
    "#             return float(match.group(1))\n",
    "#         else:\n",
    "#             return np.nan  # or raise an error if appropriate\n",
    "#     elif isinstance(tensor_value, torch.Tensor):\n",
    "#         return tensor_value.item()\n",
    "#     else:\n",
    "#         return float(tensor_value)\n",
    "\n",
    "# # Apply the function to the 'income' column\n",
    "# df_category['income_value'] = df_category['income'].apply(extract_income_value)\n",
    "\n",
    "# # Since 'income_value' is the same for each country regardless of 'Image', get unique countries and their incomes\n",
    "# country_income_df = df_category[['country', 'img_id', 'income_value']].drop_duplicates()\n",
    "\n",
    "# # Verify if 'income_value' is unique per country\n",
    "# unique_incomes = country_income_df.groupby(['country', 'img_id'])['income_value'].nunique()\n",
    "# if unique_incomes.max() > 1:\n",
    "#     print(\"Warning: Some countries have multiple income values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Sort countries based on 'income_value' in descending order\n",
    "# country_income_df_sorted = country_income_df.sort_values('income_value', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_income_df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: Create per-country subplots showing income\n",
    "# import math\n",
    "\n",
    "# # Get list of unique countries\n",
    "# unique_countries = country_income_df_sorted['country'].unique()\n",
    "# num_countries = len(unique_countries)\n",
    "\n",
    "# # Determine subplot grid size (e.g., 4 columns)\n",
    "# n_cols = 4\n",
    "# n_rows = math.ceil(num_countries / n_cols)\n",
    "\n",
    "# # Create subplots\n",
    "# fig, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows))\n",
    "# axs = axs.flatten()\n",
    "\n",
    "# for idx, country in enumerate(unique_countries):\n",
    "#     ax = axs[idx]\n",
    "#     df_country = country_income_df_sorted[country_income_df_sorted['country'] == country]\n",
    "    \n",
    "#     # Sort images by income_value ascendingly\n",
    "#     df_country_sorted = df_country.sort_values('income_value', ascending=True)\n",
    "    \n",
    "#     images = df_country_sorted['img_id']\n",
    "#     incomes = df_country_sorted['income_value']\n",
    "    \n",
    "#     ax.bar(images, incomes, color='skyblue', edgecolor='black')\n",
    "#     ax.set_title(country, fontsize=10)\n",
    "#     ax.set_ylim(0, incomes.max() * 1.1)\n",
    "#     ax.set_xlabel('Images', fontsize=8)\n",
    "#     ax.set_ylabel('Income Value', fontsize=8)\n",
    "#     ax.tick_params(axis='x', rotation=90, labelsize=0)\n",
    "#     # dont show x-axis labels\n",
    "#     ax.set_xticklabels([])\n",
    "    \n",
    "#     # Annotate income values\n",
    "#     # for i, v in enumerate(incomes):\n",
    "#     #     ax.text(i, v + incomes.max() * 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=6)\n",
    "    \n",
    "#     # Add horizontal line for mean income of the country\n",
    "#     mean_income = incomes.mean()\n",
    "#     ax.axhline(mean_income, color='red', linestyle='--', linewidth=1)\n",
    "#     ax.text(len(images)-1, mean_income, f'Mean: {mean_income:.2f}', color='red', ha='right', va='bottom', fontsize=6)\n",
    "\n",
    "# # Remove any unused subplots\n",
    "# for j in range(idx + 1, len(axs)):\n",
    "#     fig.delaxes(axs[j])\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save the figure\n",
    "# histogram_plot_path =  os.path.join(individual_figures_income_dist, 'sorted_income_per_country.png')\n",
    "# plt.savefig(histogram_plot_path, bbox_inches='tight')\n",
    "# print(f\"Saved sorted income histograms per country at: {histogram_plot_path}\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per Income Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: Create sorted bar plots of income values per income group\n",
    "\n",
    "# import math\n",
    "# # Add IncomeGroup to country_income_df\n",
    "# country_income_df['IncomeGroup'] = country_income_df['country'].map(country_income_group)\n",
    "\n",
    "# # Remove any countries without an income group\n",
    "# country_income_df = country_income_df.dropna(subset=['IncomeGroup'])\n",
    "\n",
    "# # Get list of income groups\n",
    "# income_groups = ['Rich', 'Medium', 'Poor']\n",
    "\n",
    "# # Create subplots for each income group\n",
    "# n_cols = 1\n",
    "# n_rows = len(income_groups)\n",
    "# fig, axs = plt.subplots(n_rows, n_cols, figsize=(6, 3 * n_rows), sharex=False)\n",
    "# if n_rows == 1:\n",
    "#     axs = [axs]\n",
    "\n",
    "# for idx, group in enumerate(income_groups):\n",
    "#     ax = axs[idx]\n",
    "#     df_group = country_income_df[country_income_df['IncomeGroup'] == group]\n",
    "    \n",
    "#     # Sort by income_value ascendingly\n",
    "#     df_group_sorted = df_group.sort_values('income_value', ascending=True)\n",
    "    \n",
    "#     images = df_group_sorted['img_id']\n",
    "#     incomes = df_group_sorted['income_value']\n",
    "    \n",
    "#     ax.bar(images, incomes, color='skyblue', edgecolor='black')\n",
    "#     ax.set_title(f'{group} Countries', fontsize=12)\n",
    "#     ax.set_ylim(0, incomes.max() * 1.1)\n",
    "#     ax.set_xlabel('Images', fontsize=10)\n",
    "#     ax.set_ylabel('Income Value', fontsize=10)\n",
    "#     ax.tick_params(axis='x', rotation=90, labelsize=8)\n",
    "#     ax.set_xticklabels([])\n",
    "    \n",
    "#     # # Annotate income values\n",
    "#     # for i, v in enumerate(incomes):\n",
    "#     #     ax.text(i, v + incomes.max() * 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=7)\n",
    "    \n",
    "#     # Add horizontal line for mean income of the group\n",
    "#     # mean_income = incomes.mean()\n",
    "#     # ax.axhline(mean_income, color='red', linestyle='--', linewidth=1)\n",
    "#     # ax.text(len(images)-1, mean_income, f'Mean: {mean_income:.2f}', color='red', ha='right', va='bottom', fontsize=8)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# histogram_plot_path = os.path.join(individual_figures_income_dist, 'sorted_income_histograms_per_income_group.png')\n",
    "# plt.savefig(histogram_plot_path, bbox_inches='tight')\n",
    "# print(f\"Saved sorted income histograms per income group at: {histogram_plot_path}\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the income distribution in one single plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Apply the function to the 'income' column\n",
    "# df_category['income_value'] = df_category['income'].apply(extract_income_value)\n",
    "\n",
    "# # Get all images per country\n",
    "# country_income_df = df_category[['country', 'img_id', 'income_value']].drop_duplicates()\n",
    "\n",
    "# # Verify if 'income_value' is unique per country and img_id\n",
    "# unique_incomes = country_income_df.groupby(['country', 'img_id'])['income_value'].nunique()\n",
    "# if unique_incomes.max() > 1:\n",
    "#     print(\"Warning: Some countries have multiple income values.\")\n",
    "\n",
    "# # Add IncomeGroup\n",
    "# country_income_df['IncomeGroup'] = country_income_df['country'].map(country_income_group)\n",
    "\n",
    "# # Remove any countries without an income group\n",
    "# country_income_df = country_income_df.dropna(subset=['IncomeGroup'])\n",
    "\n",
    "# # Sort countries by mean income\n",
    "# country_mean_income = country_income_df.groupby('country')['income_value'].mean().sort_values(ascending=False).index\n",
    "# country_income_df['country'] = pd.Categorical(country_income_df['country'], categories=country_mean_income, ordered=True)\n",
    "\n",
    "# # Plot combined income distribution and country-level data\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(x='country', y='income_value', data=country_income_df, order=country_mean_income, palette='Pastel1')\n",
    "# sns.swarmplot(x='country', y='income_value', data=country_income_df, color='gray', alpha=0.6, order=country_mean_income)\n",
    "\n",
    "# plt.xlabel('Country')\n",
    "# plt.ylabel('Income Value')\n",
    "# plt.title('Income Distribution per Country')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.tight_layout()\n",
    "# plot_path = os.path.join(individual_figures_income_dist, 'income_swarm_distribution_per_country.png')\n",
    "# plt.savefig(plot_path, bbox_inches='tight')\n",
    "# print(f\"Saved income distribution per country at: {plot_path}\")\n",
    "# plt.show()\n",
    "\n",
    "# # Save the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "culture-values",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
