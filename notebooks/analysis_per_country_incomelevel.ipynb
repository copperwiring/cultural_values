{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files from output directory\n",
    "output_dir = '../output_allimgs'\n",
    "output_files = os.listdir(output_dir)\n",
    "output_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "go_dataset = load_dataset(\"Anthropic/llm_global_opinions\")\n",
    "\n",
    "# load as a pandas dataframe where 'source' == wvs\n",
    "go_dataset_df = go_dataset['train'].to_pandas()\n",
    "go_dataset_wvs = go_dataset_df[go_dataset_df['source'] == 'WVS']\n",
    "go_dataset_wvs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "img_comparison = False\n",
    "img_country_comparison = True\n",
    "\n",
    "if img_comparison:\n",
    "    setting_1 = 'Image True, Country False'\n",
    "    setting_2 = 'Image False, Country False'\n",
    "    file_1 = os.path.join(output_dir, 'llava_img_True_country_False.csv')\n",
    "    file_2 = os.path.join(output_dir, 'llava_img_False_country_False.csv')\n",
    "    image_dir = 'income_comparison_images_true_country_false'\n",
    "elif img_country_comparison:\n",
    "    setting_1 = 'Image True, Country True'\n",
    "    setting_2 = 'Image False, Country True'\n",
    "    file_1 = os.path.join(output_dir, 'llava_img_True_country_True.csv')\n",
    "    file_2 = os.path.join(output_dir, 'llava_img_False_country_True.csv')\n",
    "    image_dir = 'income_comparison_images_true_country_true'\n",
    "\n",
    "# delete all files in the directory if exists\n",
    "if os.path.exists(image_dir):\n",
    "    shutil.rmtree(image_dir)\n",
    "os.makedirs(image_dir)\n",
    "\n",
    "df_1 = pd.read_csv(file_1) # image true\n",
    "df_2 = pd.read_csv(file_2) # image false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def convert_to_list(x):\n",
    "    x = ast.literal_eval(x) \n",
    "    x_list = list(x.values()) if isinstance(x, dict) else list(x)\n",
    "    return x_list\n",
    "\n",
    "def get_distribution_list(df, options_prob_col, wvs_distribution_col):\n",
    "    options_prob_dict = [convert_to_list(val) for val in df[options_prob_col]]\n",
    "    df['options_prob_list'] = pd.Series(options_prob_dict)\n",
    "    \n",
    "    wvs_distribution = [convert_to_list(val) for val in df[wvs_distribution_col]]\n",
    "    df['wvs_distribution_list'] = wvs_distribution\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Assuming df_1 and df_2 are already defined DataFrames\n",
    "df_1 = get_distribution_list(df_1, 'options_prob', 'wvs_distribution')\n",
    "df_2 = get_distribution_list(df_2, 'options_prob', 'wvs_distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.shape, df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wvs_questions = go_dataset_wvs['question'].unique()\n",
    "model_questions = df_1['question'].unique()\n",
    "\n",
    "common_questions = set(wvs_questions).intersection(set(model_questions))\n",
    "len(common_questions)\n",
    "\n",
    "# for all unique value in questions column, find \"options\" value from go_dataset_wvs and add to df_aggregated\n",
    "def add_options_to_df(questions, df_aggregated, go_dataset_wvs):\n",
    "    for question in questions:\n",
    "        options = go_dataset_wvs[go_dataset_wvs['question'] == question]['options'].values[0]\n",
    "        # create a new column with options\n",
    "        # breakpoint()\n",
    "\n",
    "        df_aggregated.loc[df_aggregated['question'] == question, 'options'] = options\n",
    "    return df_aggregated\n",
    "\n",
    "df_aggregated_1 = add_options_to_df(common_questions, df_1, go_dataset_wvs)\n",
    "df_aggregated_2 = add_options_to_df(common_questions, df_2, go_dataset_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_1.shape, df_aggregated_2.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get income from dollarstreet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main.data_handling import DataLoader\n",
    "\n",
    "data_loader = DataLoader(\"Anthropic/llm_global_opinions\", \"../data/dollarstreet/images_v2.csv\")\n",
    "dollarstreet_data = data_loader.get_dollarstreet_data()\n",
    "\n",
    "# get 'id' and 'income' columns from dollarstreet_data\n",
    "dollarstreet_id_income = dollarstreet_data[['id', 'income']]\n",
    "dollarstreet_id_income.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### add income to df_aggregated_1 and df_aggregated_2 as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add progress_apply to show progress bar\n",
    "def add_income_to_df(df_aggregated, dollarstreet_id_income):\n",
    "    df_aggregated['income'] = df_aggregated['image_id'].apply(lambda x: dollarstreet_id_income[dollarstreet_id_income['id'] == x]['income'].values[0])\n",
    "    return df_aggregated\n",
    "\n",
    "df_aggregated_1 = add_income_to_df(df_aggregated_1, dollarstreet_id_income)\n",
    "df_aggregated_2 = add_income_to_df(df_aggregated_2, dollarstreet_id_income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_1.shape, df_aggregated_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the new column with empty dictionaries\n",
    "\n",
    "# def create_joint_dict(country, df, questions, use_image=False): # TODO: use_image to be used later\n",
    "#     \"\"\" This function returns a dict which has questions as keys and distribution for that question as values\"\"\"\n",
    "#     joint_dict = {}\n",
    "#     # for each country all the unique images_ids\n",
    "#     unique_image_ids = df[df['country'] == country]['image_id'].unique() \n",
    "#     all_image_ids = unique_image_ids if use_image else unique_image_ids[:1]\n",
    "#     # for each image_id get the questions\n",
    "#     for question in questions:\n",
    "#         for image_id in all_image_ids:\n",
    "#             joint_dict[country][image_id] =[\n",
    "#                                                 [\n",
    "#                                                 question, \n",
    "#                                                 image_id,\n",
    "#                                                 df[(df['question'] == question) & (df['country'] == country) & (df['image_id'] == image_id)]['image_id'].values[0], \n",
    "#                                                 df[(df['question'] == question) & (df['country'] == country) & (df['image_id'] == image_id)]['options_prob_list'].values[0],\n",
    "#                                                 df[(df['question'] == question) & (df['country'] == country) & (df['image_id'] == image_id)]['wvs_distribution_list'].values[0],\n",
    "#                                                 df[(df['question'] == question) & (df['country'] == country) & (df['image_id'] == image_id)]['options'].values[0],\n",
    "#                                                 df[(df['question'] == question) & (df['country'] == country) & (df['image_id'] == image_id)]['img_path'].values[0],\n",
    "#                                                 df[(df['question'] == question) & (df['country'] == country) & (df['image_id'] == image_id)]['income'].values[0]\n",
    "#                                                 ]\n",
    "#                                             ]   \n",
    "#     return joint_dict\n",
    "\n",
    "\n",
    "# def create_joint_dict_all_countries(df1, df2):\n",
    "#     countries = df1['country'].unique()\n",
    "#     joint_dict_df1 = []\n",
    "#     joint_dict_df2 = []\n",
    "#     for country in tqdm(countries):\n",
    "#         questions = df_1[df_1['country'] == country]['question'].unique()\n",
    "#         joint_dict_df1.append(create_joint_dict(country, df1, questions, use_image=True))\n",
    "#         joint_dict_df2.append(create_joint_dict(country, df2, questions, use_image=False))\n",
    "\n",
    "#     return joint_dict_df1, joint_dict_df2\n",
    "\n",
    "# joint_dict_country_df1, joint_dict_country_df2 = create_joint_dict_all_countries(df_aggregated_1, df_aggregated_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the JSD i options_prob_list and wvs_distribution_list columns\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def calculate_jsd(options_prob_list, wvs_distribution_list):\n",
    "    return jensenshannon(options_prob_list, wvs_distribution_list)\n",
    "\n",
    "# add similarity column to df_aggregated which is 1-JSD\n",
    "# TODO: How to handle: invalid value encountered in divide q = q / np.sum(q, axis=axis, keepdims=True)\n",
    "\n",
    "df_aggregated_1['similarity'] = df_aggregated_1.apply(lambda x: 1 - calculate_jsd(x['options_prob_list'], x['wvs_distribution_list']), axis=1)\n",
    "df_aggregated_2['similarity'] = df_aggregated_2.apply(lambda x: 1 - calculate_jsd(x['options_prob_list'], x['wvs_distribution_list']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for country Nigeria, give unique income values\n",
    "df_aggregated_1[df_aggregated_1['country'] == 'Nigeria']['income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # print number of questions for each image_id\n",
    "# print(df_aggregated_1['image_id'].value_counts().head(2))\n",
    "# print(df_aggregated_2['image_id'].value_counts().head(2))\n",
    "\n",
    "# # print number of unique image_id per country\n",
    "# print(df_aggregated_1['country'].value_counts().tail(2))\n",
    "# print(df_aggregated_2['country'].value_counts().tail(2))\n",
    "\n",
    "\n",
    "df_aggregated_1['mean_similarity'] = df_aggregated_1.groupby('image_id')['similarity'].transform('mean')\n",
    "df_aggregated_2['mean_similarity'] = df_aggregated_2.groupby('image_id')['similarity'].transform('mean')\n",
    "\n",
    "print(df_aggregated_1.shape, df_aggregated_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort df_aggregated_1 by image_id \n",
    "df_aggregated_1 = df_aggregated_1.sort_values(by=['image_id', 'mean_similarity'], ascending=False)\n",
    "df_aggregated_2 = df_aggregated_2.sort_values(by=['image_id', 'mean_similarity'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:05<00:00,  7.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# plot mean_similarity for each image_id for each country separately.\n",
    "# each image_id has an income value, so we can plot mean_similarity vs income for each country\n",
    "\n",
    "# output image dir\n",
    "if os.path.exists(image_dir):\n",
    "    shutil.rmtree(image_dir)\n",
    "os.makedirs(image_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_similarity_vs_income(df_aggregated, image_dir):       \n",
    "    countries = df_aggregated['country'].unique()\n",
    "    for country in tqdm(countries):\n",
    "        df_country = df_aggregated[df_aggregated['country'] == country]\n",
    "        image_ids = df_country['image_id'].unique()\n",
    "        # all image_ids of a country in same plot\n",
    "        fig, ax = plt.subplots()\n",
    "        for image_id in image_ids:\n",
    "            df_image = df_country[df_country['image_id'] == image_id]\n",
    "            breakpoint()\n",
    "            ax.plot(df_image['income'].values[0], df_image['mean_similarity'].values[0], 'o')\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlim(10, 20000)\n",
    "        ax.set_xticks([10, 50, 100, 200, 500, 1000, 2000, 3000, 4000, 5000, 10000, 15000, 20000])\n",
    "        ax.get_xaxis().set_major_formatter(plt.ScalarFormatter())\n",
    "        # Rotate x axis labels 45 degrees\n",
    "        plt.xticks(rotation=45, fontsize=8)\n",
    "        ax.set_xlabel('Income in USD')\n",
    "        ax.set_ylabel('Mean Similarity')\n",
    "        ax.set_title(f'{country}')\n",
    "        # ax.legend()\n",
    "        plt.savefig(f'{image_dir}/{country}.png')\n",
    "        plt.close()\n",
    "    \n",
    "\n",
    "plot_mean_similarity_vs_income(df_aggregated_1, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the jsd values for each country side by side in bar chart\n",
    "# make country as y-axis and jsd as x-axis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_jsd(jsd_country_df1, jsd_country_df2):\n",
    "    fig, ax = plt.subplots( figsize=(10, 20))\n",
    "    # make country as y-axis and jsd as x-axis\n",
    "    countries = list(jsd_country_df1.keys())\n",
    "    jsd_values_df1 = list(jsd_country_df1.values())\n",
    "    jsd_values_df2 = list(jsd_country_df2.values())\n",
    "    x = np.arange(len(countries))\n",
    "    width = 0.35\n",
    "\n",
    "    # add the jsd values at the end of the bar\n",
    "    for i, v in enumerate(jsd_values_df1):\n",
    "        ax.text(v, i, str(round(v, 2)), color='blue', fontsize=8)\n",
    "    # text is not alligned properly. make it a little down\n",
    "    for i, v in enumerate(jsd_values_df2):\n",
    "        ax.text(v, i-0.35, str(round(v, 2)), color='red', fontsize=8)\n",
    "\n",
    "    ax.barh(x + width/2, jsd_values_df1, width, label=setting_1)\n",
    "    ax.barh(x - width/2, jsd_values_df2, width, label=setting_2)\n",
    "\n",
    "    ax.set_xlabel('Similarity (1-JSD)')\n",
    "    ax.set_ylabel('Country')\n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(countries, fontsize=10)\n",
    "    ax.legend()\n",
    "    plt.tight_layout() # to make sure the labels are not cut off\n",
    "    plt.show()\n",
    "\n",
    "plot_jsd(jsd_country_df1, jsd_country_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_jsd_difference(jsd_country_df1, jsd_country_df2):\n",
    "    # Calculate the JSD difference\n",
    "    jsd_diff = {country: jsd_country_df1[country] - jsd_country_df2[country] for country in jsd_country_df1.keys()}\n",
    "    jsd_diff = dict(sorted(jsd_diff.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    countries = list(jsd_diff.keys())\n",
    "    jsd_diff_values = list(jsd_diff.values())\n",
    "    x = np.arange(len(countries))\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 20))\n",
    "    bars = ax.barh(x, jsd_diff_values, color='blue')\n",
    "    \n",
    "    # Set labels\n",
    "    ax.set_xlabel(f'Similarity Difference ({setting_1} - {setting_2})')\n",
    "    ax.set_ylabel('Country')\n",
    "\n",
    "    # Remove the y-ticks and labels (we will add custom labels)\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Move the y-axis to x=0\n",
    "    ax.spines['left'].set_position(('data', 0))  # Move the left spine to x=0\n",
    "\n",
    "    # Customize the grid and ticks\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.tick_params(axis='y', which='both', left=True, right=False)\n",
    "\n",
    "    # Add sim values and country names at the end of the bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        width = bar.get_width()\n",
    "        country_name = countries[i]\n",
    "        if width < 0:\n",
    "            # Bar extends to the left\n",
    "            ax.text(width, bar.get_y() + bar.get_height() / 2, f'{country_name} ({width:.3f})',\n",
    "                    va='center', ha='right', color='black', fontsize=12)\n",
    "        else:\n",
    "            # Bar extends to the right\n",
    "            ax.text(width, bar.get_y() + bar.get_height() / 2, f'({width:.3f}) {country_name}', \n",
    "                    va='center', ha='left', color='black', fontsize=12)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_jsd_difference(jsd_country_df1, jsd_country_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 0.2, 0.8, 0]\n",
    "b = [0.1, 0.2, 0.9, 0]\n",
    "ans = jensenshannon(a, b)\n",
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy, copy\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# for each country, calculate jsd for each question and add the similarity value to the list\n",
    "def add_jsd_tolist(joint_dict_country_wvs_options):\n",
    "    for country_dict in tqdm(joint_dict_country_wvs_options):\n",
    "        country = list(country_dict.keys())[0]\n",
    "        for ques_vals in country_dict[country]:\n",
    "            question, dist1, dist2 = ques_vals[0], np.array(ques_vals[1]), np.array(ques_vals[2])\n",
    "            similarity = 1 - jensenshannon(dist1, dist2)\n",
    "            breakpoint()\n",
    "            ques_vals.append(similarity)\n",
    "\n",
    "    return joint_dict_country_wvs_options\n",
    "\n",
    "joint_dict_df1 = copy.deepcopy(joint_dict_country_df1)\n",
    "joint_dict_df2 = copy.deepcopy(joint_dict_country_df2)\n",
    "\n",
    "jsd_df1 = add_jsd_tolist(joint_dict_df1)\n",
    "jsd_df2 = add_jsd_tolist(joint_dict_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsd_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove nan values\n",
    "jsd_values_df1 = {country: [val[6] for val in jsd_dict[country] if not np.isnan(val[6])] for jsd_dict in jsd_df1 for country, jsd_vals in jsd_dict.items()}\n",
    "jsd_values_df2 = {country: [val[6] for val in jsd_dict[country] if not np.isnan(val[6])] for jsd_dict in jsd_df2 for country, jsd_vals in jsd_dict.items()}\n",
    "\n",
    "# # calculate the mean of jsd values per country\n",
    "jsd_min_max_mean_df1 = {country: [np.min(val), np.max(val), np.mean(val)] for country, val in jsd_values_df1.items()}\n",
    "jsd_min_max_mean_df2 = {country: [np.min(val), np.max(val), np.mean(val)] for country, val in jsd_values_df2.items()}\n",
    "\n",
    "print(jsd_min_max_mean_df1)\n",
    "print(jsd_min_max_mean_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split jsd_selected_df1 such that one has questions etc with similarity  <= 0.5 and other has > 0.5\n",
    "# do this for all countries\n",
    "low_threshold = 0.3\n",
    "high_threshold = 0.8\n",
    "\n",
    "def split_jsd(values):\n",
    "    jsd_low_split = {}\n",
    "    jsd_high_split = {}\n",
    "    for country_dict in tqdm(values):\n",
    "        country = list(country_dict.keys())[0]\n",
    "        jsd_low = []; jsd_high = []; \n",
    "        for ques_vals in country_dict[country]:\n",
    "            if ques_vals[6] <= low_threshold:\n",
    "                breakpoint()\n",
    "                jsd_low.append(ques_vals.copy())\n",
    "\n",
    "            elif ques_vals[6] >= high_threshold:\n",
    "                jsd_high.append(ques_vals.copy())\n",
    "        \n",
    "        jsd_low_split[country] = jsd_low\n",
    "        jsd_high_split[country] = jsd_high\n",
    "        \n",
    "    return jsd_low_split, jsd_high_split\n",
    "\n",
    "jsd_low_split_df1, jsd_high_split_df1 = split_jsd(jsd_df1)\n",
    "jsd_low_split_df2, jsd_high_split_df2 = split_jsd(jsd_df2)\n",
    "\n",
    "print(f\" JSD values <= {low_threshold}: {jsd_low_split_df1}\")\n",
    "\n",
    "print(f\"DF1: sum of values <= {low_threshold}: {sum([len(val) for val in jsd_low_split_df1.values()])}\")\n",
    "print(f\"DF1: sum of values >= {high_threshold}: {sum([len(val) for val in jsd_high_split_df1.values()])}\")\n",
    "\n",
    "print(f\"DF2: sum of values <= {low_threshold}: {sum([len(val) for val in jsd_low_split_df2.values()])}\")\n",
    "print(f\"DF2: sum of values >= {high_threshold}: {sum([len(val) for val in jsd_high_split_df2.values()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsd_low_split_df1['Iran']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the common questions in both low similarity for df1 and df2\n",
    "# questions for first value of the list of lists\n",
    "\n",
    "def get_common_questions(df1, df2):\n",
    "    common_questions = {}\n",
    "    for country in df1.keys():\n",
    "        questions_df1 = [val[0] for val in df1[country]]\n",
    "        questions_df2 = [val[0] for val in df2[country]]\n",
    "        breakpoint()\n",
    "        common_questions[country] = set(questions_df1).intersection(set(questions_df2))\n",
    "    return common_questions\n",
    "\n",
    "common_questions = get_common_questions(jsd_low_split_df1, jsd_low_split_df2)\n",
    "common_questions_count = {key: len(value) for key, value in common_questions.items()}\n",
    "print(common_questions_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cultural_values",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
