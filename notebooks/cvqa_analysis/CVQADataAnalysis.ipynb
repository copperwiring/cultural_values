{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_questions_file = '../categorized_questions.jsonl'\n",
    "\n",
    "# read categorized questions\n",
    "categorized_questions = []\n",
    "with open(categorized_questions_file, 'r') as f:\n",
    "    for line in f:\n",
    "        categorized_questions.append(json.loads(line))\n",
    "\n",
    "# check if common_questions are same as categorized_questions\n",
    "categorized_questions_list = [list(q.values())[0] for q in categorized_questions]\n",
    "\n",
    "# create a dictionary to map questions to their categories\n",
    "question_to_category = {q['Question']: q['Category'] for q in categorized_questions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of unique categories: 15\n",
      "['A. Social values and attitudes', 'B. Religion and spirituality', 'C. Science and technology', 'D. Politics and policy', 'E. Demographics', 'G. International affairs', 'I. Gender and LGBTQ', 'J. News habits and media', 'K. Immigration and migration', 'L. Family and relationships', 'M. Race and ethnicity', 'N. Economy and work', 'O. Regions and countries', 'P. Methodological research', 'Q. Security']\n"
     ]
    }
   ],
   "source": [
    "# all unique categories in question_to_category\n",
    "unique_categories = sorted(set(question_to_category.values()))\n",
    "print(f\"Lenght of unique categories: {len(unique_categories)}\")\n",
    "print(unique_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load of the CSV Data\n",
    "- CSV Data: CSV Files for 17 countries\n",
    "- Dollarstreet data is excluded because it is across more countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cvqa_wvs_metadata_llava-v1.6-vicuna-13b_True_results.csv', 'cvqa_wvs_metadata_llava-v1.6-vicuna-13b_False_results.csv', 'cvqa_wvs_metadata_llava-v1.6-34b_True_results.csv', 'cvqa_wvs_metadata_llava-v1.6-34b_False_results.csv']\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "import ast\n",
    "\n",
    "# List all files in the directory\n",
    "directory = \"/home/vsl333/cultural_values/notebooks/outputs\"\n",
    "country_image_file_list = ['cvqa_wvs_metadata_llava-v1.6-vicuna-13b_True_results.csv', 'cvqa_wvs_metadata_llava-v1.6-vicuna-13b_False_results.csv',\n",
    "                            # 'cvqa_wvs_metadata_llava-v1.6-34b_True_results.csv', 'cvqa_wvs_metadata_llava-v1.6-34b_False_results.csv']\n",
    "                            'cvqa_wvs_metadata_llava-next-72b-hf_True_results.csv', 'cvqa_wvs_metadata_llava-next-72b-hf_False_results.csv',]\n",
    "print(country_image_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map question to thieir question category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a combioned dataframe for both country and image level data\n",
    "- Remove all rows where sum <98\n",
    "- All 4 dataframes should have data for same country-image pairs\n",
    "- Concatenate image and text dataframes\n",
    "- 'Image' colun will be True for Image level data and False for Country level data\n",
    "- Compute JSD and Similarity for each question per countriy (across all categories)in 'jsd' and 'similarity' columns\n",
    "- JSD: Jensen Shannon Divergence, Similarity is computed as 1 - JSD\n",
    "- 'coutry_mean_similarity' and 'country_mean_jsd' columns have mean similarity and JSD values for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: cvqa_wvs_metadata_llava-v1.6-vicuna-13b_True_results.csv Has Image: False Model Size: 13b\n",
      "Processing file: cvqa_wvs_metadata_llava-v1.6-vicuna-13b_False_results.csv Has Image: True Model Size: 13b\n",
      "Processing file: cvqa_wvs_metadata_llava-v1.6-34b_True_results.csv Has Image: False Model Size: 34b\n",
      "Processing file: cvqa_wvs_metadata_llava-v1.6-34b_False_results.csv Has Image: True Model Size: 34b\n",
      "Pre filtered shape: (60756, 25)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "all_incorrect_df = pd.DataFrame()\n",
    "for idx, each_file in enumerate(country_image_file_list):\n",
    "    \n",
    "    # 'True' => Country was in the prompt, 'False' => Country was not in the prompt, only image was used\n",
    "    has_image = 'True' if 'False' in each_file else 'False' if 'True' in each_file else print(\"Missing: Neither 'True' nor 'False' is present in the file name\")\n",
    "    modelsize = '13b' if '13b' in each_file else '34b' if '34b' in each_file else '72b' if '72b' in each_file else print(\"Missing: Model size is not present in the file name\")\n",
    "    \n",
    "    print(f\"Processing file: {each_file}\", f\"Has Image: {has_image}\", f\"Model Size: {modelsize}\")\n",
    "    each_data = pd.read_csv(os.path.join(directory, each_file))\n",
    "    data = each_data.copy()\n",
    "\n",
    "    # Add category column to the DataFrame\n",
    "    breakpoint()\n",
    "    # data['img_category'] = data['image_path'].apply(lambda x: x.split('/')[-1].split('.')[0].split('_')[1:-2])\n",
    "    data['img_category'] = data['image_path'].apply(lambda x: x.split('/')[-2:-1][0])\n",
    "\n",
    "    # Example gt and pred (list of lists)\n",
    "    gt = [ast.literal_eval(x) for x in data['selection_answers'].tolist()] # there are prob distrbutions of human answers\n",
    "    pred = [ast.literal_eval(x) for x in data['prob_percent_values'].tolist()] # there are prob distrbutions of model answers\n",
    "\n",
    "    # Original DataFrame, retaining all columns from `data`\n",
    "    df = data.copy()\n",
    "\n",
    "    # Keep track of matching indices\n",
    "    matching_indices = [i for i, (g, p) in enumerate(zip(gt, pred)) if len(g) == len(p)]\n",
    "\n",
    "    # Filter rows where len(g) == len(p)\n",
    "    filtered_gt_pred = [(g, p) for g, p in zip(gt, pred) if len(g) == len(p)]\n",
    "\n",
    "    # If there are any matching rows\n",
    "    if filtered_gt_pred:\n",
    "        gt_filtered, pred_filtered = zip(*filtered_gt_pred)\n",
    "\n",
    "        # Calculate JSD\n",
    "        jsd = [distance.jensenshannon(g, p) for g, p in zip(gt_filtered, pred_filtered)]\n",
    "        similarity = [1 - value for value in jsd]\n",
    "\n",
    "        try:\n",
    "            # Add JSD and similarity values back to the DataFrame\n",
    "            df.loc[matching_indices, 'jsd'] = jsd\n",
    "            df.loc[matching_indices, 'similarity'] = similarity\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing JSD and similarity for indices {matching_indices}: {e}\")\n",
    "            breakpoint()\n",
    "    else:\n",
    "        df['jsd'] = None  # or handle the case accordingly\n",
    "        df['similarity'] = None\n",
    "\n",
    "    # Set JSD and similarity to NaN or a placeholder for rows that were filtered out\n",
    "    df['jsd'] = pd.to_numeric(df['jsd'], errors='coerce')\n",
    "    df['similarity'] = pd.to_numeric(df['similarity'], errors='coerce')\n",
    "\n",
    "    df['Image'] = 'False' if has_image == 'False' else 'True' if has_image == 'True' else print(\"Something missing! Image is not True or False\")\n",
    "    df['model_size'] = modelsize\n",
    "\n",
    "    # Calculate mean of jsd and similarity per country per 'Image' column and add new col 'mean_jsd' and 'mean_similarity'\n",
    "    df['country_mean_jsd'] = df.groupby(['country', 'Image'])['jsd'].transform('mean')\n",
    "    df['coutry_mean_similarity'] = df.groupby(['country', 'Image'])['similarity'].transform('mean')\n",
    "        \n",
    "    # Append results to list\n",
    "    results.append(df)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_results = pd.concat(results)\n",
    "print(f\"Pre filtered shape: {final_results.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post filtered shape: (60440, 25)\n"
     ]
    }
   ],
   "source": [
    "# drop any rows with NaN values\n",
    "final_results = final_results.dropna()\n",
    "print(f\"Post filtered shape: {final_results.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selection_answers</th>\n",
       "      <th>prob_percent_values</th>\n",
       "      <th>question_text</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [selection_answers, prob_percent_values, question_text, country]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all rows where jsd is NaN, display selection_answers and prob_percent_values\n",
    "final_results[final_results['jsd'].isnull()][['selection_answers', 'prob_percent_values', 'question_text', 'country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: count, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>sum_prob_percent_sorted</th>\n",
       "      <th>img_category</th>\n",
       "      <th>jsd</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <th>model_size</th>\n",
       "      <th>image_path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt, sum_prob_percent_sorted, img_category, jsd, similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show all rows in final_result where sum_prob_percent_sorted < 99\n",
    "mnp = final_results[final_results['sum_prob_percent_sorted'] < 99][['image_path', 'prompt', 'sum_prob_percent_sorted', 'Image', 'model_size', 'img_category', 'jsd', 'similarity']]\n",
    "print(mnp[['Image', 'model_size']].value_counts())\n",
    "\n",
    "pd.set_option('display.max_colwidth', 300)\n",
    "mnp.groupby(['Image', 'model_size','image_path']).count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter rows where sum_prob_percent_sorted <99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the total data: (60440, 25)\n",
      "Size of the filtered data: (60440, 25)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size of the total data: {final_results.shape}\")\n",
    "# Filter rows where sum_prob_percent_sorted <99\n",
    "filtered_final_result = final_results[final_results['sum_prob_percent_sorted'] > 99]\n",
    "print(f\"Size of the filtered data: {filtered_final_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 'question_topic' to both dataframes\n",
    "- 'question_topic' is the column which has each question mapped to a broad topic\n",
    "- Broad topics are: {'B. Religion and spirituality', 'E. Demographics', 'A. Social values and attitudes', 'D. Politics and policy', 'O. Regions and countries', 'J. News habits and media', 'G. International affairs', 'M. Race and ethnicity', 'N. Economy and work', 'P. Methodological research', 'C. Science and technology', 'K. Immigration and migration', 'L. Family and relationships', 'Q. Security', 'I. Gender and LGBTQ'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Country Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_id', 'image_path', 'country', 'image_code', 'income',\n",
       "       'question_text', 'country_prompt', 'generic_prompt', 'option_labels',\n",
       "       'full_options', 'prompt', 'options', 'top10_token_prob',\n",
       "       'prob_percent_sorted', 'sum_prob_percent_sorted', 'prob_percent_keys',\n",
       "       'prob_percent_values', 'selection_answers', 'img_category', 'jsd',\n",
       "       'similarity', 'Image', 'model_size', 'country_mean_jsd',\n",
       "       'coutry_mean_similarity', 'question_topic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_final_result['question_topic'] = filtered_final_result['question_text'].map(question_to_category)\n",
    "filtered_final_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "img_id                     0\n",
       "image_path                 0\n",
       "country                    0\n",
       "image_code                 0\n",
       "income                     0\n",
       "question_text              0\n",
       "country_prompt             0\n",
       "generic_prompt             0\n",
       "option_labels              0\n",
       "full_options               0\n",
       "prompt                     0\n",
       "options                    0\n",
       "top10_token_prob           0\n",
       "prob_percent_sorted        0\n",
       "sum_prob_percent_sorted    0\n",
       "prob_percent_keys          0\n",
       "prob_percent_values        0\n",
       "selection_answers          0\n",
       "img_category               0\n",
       "jsd                        0\n",
       "similarity                 0\n",
       "Image                      0\n",
       "model_size                 0\n",
       "country_mean_jsd           0\n",
       "coutry_mean_similarity     0\n",
       "question_topic             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count rows where nan values are present\n",
    "filtered_final_result.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_countries = [\"United States\", \"France\", \"South Korea\", \"Italy\"]\n",
    "medium_countries = [\"Brazil\", \"Mexico\", \"China\"]\n",
    "poor_countries = [\"Pakistan\", \"Nigeria\", \"Vietnam\"]\n",
    "\n",
    "country_list = rich_countries + medium_countries + poor_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate by  question categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Brazil', 'China', 'France', 'Italy', 'Mexico', 'Nigeria',\n",
       "       'Pakistan', 'South Korea', 'United States', 'Vietnam'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_countries = filtered_final_result['country'].unique()\n",
    "unique_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United States',\n",
       " 'France',\n",
       " 'South Korea',\n",
       " 'Italy',\n",
       " 'Brazil',\n",
       " 'Mexico',\n",
       " 'China',\n",
       " 'Pakistan',\n",
       " 'Nigeria',\n",
       " 'Vietnam']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results_country_order = [country for country in country_list if country in unique_countries]\n",
    "results_country_order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Marginal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Func for marginal distribution calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_distributions(distributions):\n",
    "    # Ensure all distributions are lists (not strings)\n",
    "    distributions = [ast.literal_eval(dist) if isinstance(dist, str) else dist for dist in distributions]\n",
    "    \n",
    "    # Ensure all distributions are valid lists of numbers\n",
    "    valid_distributions = [np.array(dist, dtype=float) for dist in distributions if isinstance(dist, list)]\n",
    "\n",
    "    # Calculate the average distribution\n",
    "    average_dist =  np.mean(np.array(valid_distributions), axis=0).tolist()\n",
    "    \n",
    "    return average_dist\n",
    "\n",
    "# General function to calculate marginal distribution and merge it back into the DataFrame\n",
    "def calculate_and_merge_marginal_distribution(df, groupby_columns, target_column, new_column_name):\n",
    "    \"\"\"\n",
    "    Generalized function to calculate marginal distribution, reset index, and merge back to the original DataFrame.\n",
    "    \"\"\"\n",
    "    marginal_df = (\n",
    "        df.groupby(groupby_columns)[target_column]\n",
    "        .apply(average_distributions)\n",
    "        .reset_index(name=new_column_name)\n",
    "    )\n",
    "    return df.merge(marginal_df, on=groupby_columns, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Func to compute jsd and 1-jsd for the marginalized distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# Function to calculate Jensen-Shannon Divergence (JSD)\n",
    "def calculate_jsd(p, q):\n",
    "    if len(p) == 0 or len(q) == 0:  # Check for empty distributions\n",
    "        return None  # or return a specific value indicating no valid distributions\n",
    "    return jensenshannon(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to compute jsd and similarity (1-jsd) for \n",
    "- each question topic\n",
    "- marginal distribution distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['img_id', 'image_path', 'country', 'image_code', 'income',\n",
       "       'question_text', 'country_prompt', 'generic_prompt', 'option_labels',\n",
       "       'full_options', 'prompt', 'options', 'top10_token_prob',\n",
       "       'prob_percent_sorted', 'sum_prob_percent_sorted', 'prob_percent_keys',\n",
       "       'prob_percent_values', 'selection_answers', 'img_category', 'jsd',\n",
       "       'similarity', 'Image', 'model_size', 'country_mean_jsd',\n",
       "       'coutry_mean_similarity', 'question_topic', 'question_topic_mean_jsd',\n",
       "       'question_topic_mean_similarity',\n",
       "       'question_topic_country_mean_similarity', 'md_topic_pred',\n",
       "       'md_topic_gt', 'md_all_pred', 'md_all_gt', 'md_jsd_topic',\n",
       "       'md_sim_topic', 'md_jsd_overall', 'md_sim_overall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each question_topic, calculate mean of jsd and similarity per country and save as different df \n",
    "# save all dfs in a dictionary\n",
    "\n",
    "# Calculate mean of 'jsd' per 'question_topic', Image'. This seems useless\n",
    "filtered_final_result['question_topic_mean_jsd'] = filtered_final_result.groupby(['question_topic', 'Image', 'model_size'])['jsd'].transform('mean')\n",
    "# Calculate mean of 'similarity' per 'question_topic','Image'. Thiss eems useless\n",
    "\n",
    "filtered_final_result['question_topic_mean_similarity'] = filtered_final_result.groupby(['question_topic', 'Image', 'model_size'])['similarity'].transform('mean')\n",
    "# Calculate mean of 'question_topic_mean_similarity' per country\n",
    "filtered_final_result['question_topic_country_mean_similarity'] = filtered_final_result.groupby(['question_topic', 'country', 'Image', 'model_size'])['similarity'].transform('mean')\n",
    "\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_topic', 'question_text', 'Image', 'model_size'], 'prob_percent_values', 'md_topic_pred'\n",
    ")\n",
    "\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_topic', 'question_text', 'Image', 'model_size'], 'selection_answers', 'md_topic_gt'\n",
    ")\n",
    "\n",
    "# Step 3 and 4: Calculate marginalized model prediction and ground truth across all images per question only\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_text', 'Image', 'model_size'], 'prob_percent_values', 'md_all_pred'\n",
    ")\n",
    "\n",
    "filtered_final_result = calculate_and_merge_marginal_distribution(\n",
    "    filtered_final_result, ['question_text', 'Image', 'model_size'], 'selection_answers', 'md_all_gt'\n",
    ")\n",
    "\n",
    "# Calculate JSD for each question topic\n",
    "filtered_final_result['md_jsd_topic'] = filtered_final_result.apply(\n",
    "    lambda row: calculate_jsd(row['md_topic_pred'], row['md_topic_gt']), axis=1\n",
    ")\n",
    "filtered_final_result['md_sim_topic'] = 1 - filtered_final_result['md_jsd_topic']\n",
    "\n",
    "# Calculate JSD for overall predictions and ground truth\n",
    "filtered_final_result['md_jsd_overall'] = filtered_final_result.apply(\n",
    "    lambda row: calculate_jsd(row['md_all_pred'], row['md_all_gt']), axis=1\n",
    ")\n",
    "filtered_final_result['md_sim_overall'] = 1 - filtered_final_result['md_jsd_overall']\n",
    "\n",
    "# print column names\n",
    "filtered_final_result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60440, 37)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_final_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each question_topic, calculate mean of jsd and similarity per country and save as different df \n",
    "# # save all dfs in a dictionary\n",
    "\n",
    "# import shutil\n",
    "# question_outputs_dir = 'cvqa_analysis/cvqa_ques_category'\n",
    "\n",
    "# # delete directory if already exist\n",
    "# if os.path.exists(question_outputs_dir):\n",
    "#     shutil.rmtree(question_outputs_dir)\n",
    "#     print(f\"Existed! Deleted {question_outputs_dir} directory\")\n",
    "\n",
    "# # create directory\n",
    "# os.makedirs(question_outputs_dir)\n",
    "# print(f\"Created {question_outputs_dir} directory\")  \n",
    "\n",
    "# # save final_result as csv\n",
    "# filtered_final_result.to_csv(f\"{question_outputs_dir}/all_category_results.csv\", index=False)\n",
    "\n",
    "# df_category_similarity = {}\n",
    "\n",
    "# for category in filtered_final_result['question_topic'].unique():\n",
    "#     df_category = filtered_final_result[filtered_final_result['question_topic'] == category]\n",
    "\n",
    "#     # calculate mean of jsd and similarity per country\n",
    "#     df_category['question_topic_mean_jsd'] = df_category.groupby(['country', 'Image'])['jsd'].transform('mean')\n",
    "#     df_category['question_topic_mean_similarity'] = df_category.groupby(['country', 'Image'])['similarity'].transform('mean')\n",
    "\n",
    "#     df_category_similarity[category] = df_category\n",
    "\n",
    "#     df_category_similarity[category].to_csv(f\"{question_outputs_dir}/{category}_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final df per (question)topic category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory to save csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed! Deleted topic_csv directory\n",
      "Question Topic Level Data will be saved at: topic_csv\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "question_topic_ouput_dir = 'topic_csv'\n",
    "\n",
    "# delete directory if already exist. Include subdirectories\n",
    "if os.path.exists(question_topic_ouput_dir):\n",
    "    shutil.rmtree(question_topic_ouput_dir)\n",
    "    print(f\"Existed! Deleted {question_topic_ouput_dir} directory\")\n",
    "\n",
    "# create directory\n",
    "os.makedirs(question_topic_ouput_dir)\n",
    "print(f\"Question Topic Level Data will be saved at: {question_topic_ouput_dir}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['People_and_everyday_life' 'sports_and_recreation'\n",
      " 'public_figure_and_pop_culture' 'Objects' 'Brands' 'Geography'\n",
      " 'Cooking_and_food' 'tradition']\n"
     ]
    }
   ],
   "source": [
    "unique_img_categories = filtered_final_result['img_category'].unique()\n",
    "print(unique_img_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/all_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/A. Social values and attitudes.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:00<00:04,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/B. Religion and spirituality.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:01<00:05,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/C. Science and technology.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:04<00:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/D. Politics and policy.csv\n",
      "Saved data: topic_csv/E. Demographics.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:04<00:06,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/G. International affairs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:05<00:04,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/I. Gender and LGBTQ.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:05<00:03,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/J. News habits and media.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:05<00:03,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/K. Immigration and migration.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:07<00:02,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/L. Family and relationships.csv\n",
      "Saved data: topic_csv/M. Race and ethnicity.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [00:08<00:02,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/N. Economy and work.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [00:10<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/O. Regions and countries.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [00:16<00:02,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/P. Methodological research.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:17<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data: topic_csv/Q. Security.csv\n",
      "Question Topic Level Data saved at: topic_csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filtered_final_result.to_csv(f\"{question_topic_ouput_dir}/all_results.csv\", index=False)\n",
    "print(f\"Saved data: {question_topic_ouput_dir}/all_results.csv\")\n",
    "\n",
    "# Create separate DataFrames per question topic and save them\n",
    "df_category_similarity = {}\n",
    "question_topics = sorted(filtered_final_result['question_topic'].unique())\n",
    "\n",
    "for topic in tqdm(question_topics):\n",
    "    df_question_topic = filtered_final_result[filtered_final_result['question_topic'] == topic]\n",
    "    df_category_similarity[topic] = df_question_topic\n",
    "    df_question_topic.to_csv(f\"{question_topic_ouput_dir}/{topic}.csv\", index=False)\n",
    "    print(f\"Saved data: {question_topic_ouput_dir}/{topic}.csv\")\n",
    "\n",
    "print(f\"Question Topic Level Data saved at: {question_topic_ouput_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A. Social values and attitudes', 'B. Religion and spirituality', 'C. Science and technology', 'D. Politics and policy', 'E. Demographics', 'G. International affairs', 'I. Gender and LGBTQ', 'J. News habits and media', 'K. Immigration and migration', 'L. Family and relationships', 'M. Race and ethnicity', 'N. Economy and work', 'O. Regions and countries', 'P. Methodological research', 'Q. Security'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_category_similarity.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3735556707.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[25], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    so that notebook breaks here if you run from top\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "so that notebook breaks here if you run from top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Bootstrapping for Statistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure 'similarity' is numeric\n",
    "filtered_final_result['similarity'] = pd.to_numeric(filtered_final_result['similarity'], errors='coerce')\n",
    "# Drop rows with NaN similarity scores\n",
    "filtered_final_result = filtered_final_result.dropna(subset=['similarity'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to perform bootstrapping on your similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bootstrap_mean(data, n_bootstrap=10000):\n",
    "#     n = len(data)\n",
    "#     bootstrap_means = np.empty(n_bootstrap)\n",
    "#     for i in range(n_bootstrap):\n",
    "#         sample = np.random.choice(data, size=n, replace=True)\n",
    "#         bootstrap_means[i] = np.mean(sample)\n",
    "#     return bootstrap_means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Confidence Intervals and P-values\n",
    "\n",
    "Perform bootstrapping for each group (e.g., per question_topic, Image, model_size) to compute confidence intervals and p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap_results = []\n",
    "\n",
    "# # Group by 'question_topic', 'Image', 'model_size'\n",
    "# grouped = filtered_final_result.groupby(['question_topic', 'Image', 'model_size'])\n",
    "\n",
    "# for name, group in grouped:\n",
    "#     similarity_scores = group['similarity'].values\n",
    "    \n",
    "#     # Skip groups with insufficient data\n",
    "#     if len(similarity_scores) < 5:\n",
    "#         continue\n",
    "    \n",
    "#     # Perform bootstrapping\n",
    "#     bootstrap_means = bootstrap_mean(similarity_scores)\n",
    "    \n",
    "#     # Calculate observed mean\n",
    "#     observed_mean = np.mean(similarity_scores)\n",
    "    \n",
    "#     # Calculate 95% confidence interval\n",
    "#     ci_lower = np.percentile(bootstrap_means, 2.5)\n",
    "#     ci_upper = np.percentile(bootstrap_means, 97.5)\n",
    "    \n",
    "#     # Perform hypothesis testing (e.g., test if mean similarity > 0.5)\n",
    "#     p_value = np.mean(bootstrap_means <= 0.5)\n",
    "    \n",
    "#     # Store results\n",
    "#     bootstrap_results.append({\n",
    "#         'question_topic': name[0],\n",
    "#         'Image': name[1],\n",
    "#         'model_size': name[2],\n",
    "#         'observed_mean_similarity': observed_mean,\n",
    "#         'ci_lower': ci_lower,\n",
    "#         'ci_upper': ci_upper,\n",
    "#         'p_value': p_value\n",
    "#     })\n",
    "\n",
    "# # Convert results to DataFrame\n",
    "# bootstrap_df = pd.DataFrame(bootstrap_results)\n",
    "\n",
    "# # Display results\n",
    "# print(bootstrap_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Groups Using Hypothesis Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal, getcontext\n",
    "\n",
    "# Set precision for Decimal operations\n",
    "getcontext().prec = 20  # Adjust precision as needed\n",
    "\n",
    "def bootstrap_mean_diff(data1, data2, n_bootstrap=100000):\n",
    "    observed_diff = np.mean(data1) - np.mean(data2)\n",
    "    combined = np.concatenate([data1, data2])\n",
    "    n1 = len(data1)\n",
    "    mean_diffs = np.empty(n_bootstrap)\n",
    "    for i in range(n_bootstrap):\n",
    "        np.random.shuffle(combined)\n",
    "        sample1 = combined[:n1]\n",
    "        sample2 = combined[n1:]\n",
    "        mean_diffs[i] = np.mean(sample1) - np.mean(sample2)\n",
    "    extreme_count = np.sum(np.abs(mean_diffs) >= np.abs(observed_diff))\n",
    "    # Convert extreme_count to standard Python int\n",
    "    p_value = Decimal(int(extreme_count)) / Decimal(n_bootstrap)\n",
    "    return observed_diff, p_value\n",
    "\n",
    "bootstrap_results = []\n",
    "\n",
    "grouped = filtered_final_result.groupby(['question_topic', 'model_size'])\n",
    "\n",
    "for name, group in grouped:\n",
    "    group_true = group[group['Image'] == 'True']['similarity'].values\n",
    "    group_false = group[group['Image'] == 'False']['similarity'].values\n",
    "    if len(group_true) < 5 or len(group_false) < 5:\n",
    "        continue\n",
    "    observed_diff, p_value = bootstrap_mean_diff(group_true, group_false, n_bootstrap=1000000)\n",
    "    bootstrap_results.append({\n",
    "        'question_topic': name[0],\n",
    "        'model_size': name[1],\n",
    "        # 'observed_mean_diff': observed_diff,\n",
    "        'p_value': float(p_value)\n",
    "    })\n",
    "\n",
    "bootstrap_df = pd.DataFrame(bootstrap_results)\n",
    "\n",
    "# Adjust display format to show p-values with higher precision\n",
    "pd.set_option('display.float_format', '{:.10e}'.format)\n",
    "\n",
    "print(bootstrap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust display format to show p-values with higher precision\n",
    "pd.set_option('display.float_format', '{:.10e}'.format)\n",
    "\n",
    "print(bootstrap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Break again here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Get the unique categories\n",
    "categories = df_category_similarity.keys()\n",
    "\n",
    "# Determine the number of subplots needed\n",
    "num_categories = len(categories)\n",
    "num_cols = 2\n",
    "num_rows = (num_categories + 1) // num_cols\n",
    "\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(16, num_rows * 4))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Initialize variables for the legend\n",
    "legend_handles = None\n",
    "legend_labels = None\n",
    "\n",
    "# Iterate through each category and create a subplot\n",
    "for idx, category in enumerate(categories):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get the dataframe for the current category\n",
    "    cat_df = df_category_similarity[category]\n",
    "    \n",
    "    # Filter and sort the dataframe\n",
    "    cat_df = cat_df[['country', 'question_topic_mean_jsd', 'question_topic_mean_similarity', 'Image']].drop_duplicates()\n",
    "    cat_df = cat_df.sort_values(['country', 'Image'])\n",
    "    \n",
    "    # Filter cat_df to only include countries in results_country_order\n",
    "    cat_df = cat_df[cat_df['country'].isin(results_country_order)]\n",
    "    \n",
    "    # If cat_df is empty, skip this plot\n",
    "    if cat_df.empty:\n",
    "        # Remove the axis\n",
    "        fig.delaxes(ax)\n",
    "        continue\n",
    "    \n",
    "    # Set 'country' as a categorical variable with ordered categories\n",
    "    cat_df['country'] = pd.Categorical(cat_df['country'], categories=results_country_order, ordered=True)\n",
    "    \n",
    "    # Sort cat_df by 'country' to ensure correct order\n",
    "    cat_df = cat_df.sort_values('country')\n",
    "    \n",
    "    # Create a bar plot\n",
    "    sns.barplot(\n",
    "        x='country',\n",
    "        y='question_topic_mean_similarity',\n",
    "        hue='Image',\n",
    "        data=cat_df,\n",
    "        palette='viridis',\n",
    "        ax=ax\n",
    "    )\n",
    "    \n",
    "    # Collect legend handles and labels from the first subplot\n",
    "    if legend_handles is None:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        new_labels = ['Only Country, No Image' if label == 'False' else 'Only Image, No Country' for label in labels]\n",
    "        legend_handles = handles\n",
    "        legend_labels = new_labels\n",
    "    \n",
    "    # Remove legend from the subplot\n",
    "    ax.get_legend().remove()\n",
    "    \n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Country')\n",
    "    ax.set_ylabel('Question Topic Mean Similarity')\n",
    "    ax.set_title(f'{category}', fontsize=10)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "# Remove any unused subplots\n",
    "for idx in range(num_categories, len(axes)):\n",
    "    fig.delaxes(axes[idx])\n",
    "\n",
    "# Add a single legend to the figure\n",
    "fig.legend(legend_handles, legend_labels, title='Image', fontsize=8, loc='upper right')\n",
    "\n",
    "# Adjust layout with vertical space between subplots\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=1, right=0.85)  # Adjust 'right' to make space for the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort countries in order of income (High Income to Low Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rich_countries = [\"Russia\", \"Romania\", \"France\", \"Spain\", \"South Korea\"]\n",
    "# medium_countries = [\"Brazil\", \"Indonesia\", \"Mexico\", \"Philippines\", \"Mongolia\", \"China\", \"Colombia\"]\n",
    "# poor_countries = [\"Ethiopia\", \"Nigeria\", \"Egypt\", \"Kenya\", \"Pakistan\"]\n",
    "\n",
    "\n",
    "# country_order= rich_countries + medium_countries + poor_countries \n",
    "# print(len(country_order))\n",
    "# # sort final result by country_order and put it in a new dataframe\n",
    "# final_result_sorted = final_result.set_index('country').loc[country_order].reset_index()\n",
    "# final_result_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the color palette for Countries Mapped to Income Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_mapping = {}\n",
    "for country in rich_countries:\n",
    "    country_mapping[country] = 'rich'\n",
    "for country in medium_countries:\n",
    "    country_mapping[country] = 'medium'\n",
    "for country in poor_countries:\n",
    "    country_mapping[country] = 'poor'\n",
    "\n",
    "# Define a color palette for the categories\n",
    "# Define a color palette for the categories\n",
    "category_palette = {\n",
    "    'rich': 'darkgreen',\n",
    "    'medium': 'lightgreen',\n",
    "    'poor': 'lightcoral'\n",
    "}\n",
    "\n",
    "# Map each country to its respective category\n",
    "final_result_sorted['country_group'] = final_result_sorted['country'].map(country_mapping)\n",
    "# Map colors based on the category_group\n",
    "final_result_sorted['income_color'] = final_result_sorted['country_group'].map(category_palette)\n",
    "final_result_sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the color palette for Countries Mapped to Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_regions = {\"Russia\": \"Europe\", \"Romania\": \"Europe\", \"France\": \"Europe\", \"Spain\": \"Europe\", \"South Korea\": \"Asia\",\n",
    "                \"Brazil\": \"South America\", \"Indonesia\": \"Asia\", \"Mexico\": \"North America\", \"Philippines\": \"Asia\",\n",
    "                \"Mongolia\": \"Asia\", \"China\": \"Asia\", \"Colombia\": \"South America\", \"Ethiopia\": \"Africa\",\n",
    "                \"Nigeria\": \"Africa\", \"Egypt\": \"Africa\", \"Kenya\": \"Africa\", \"Pakistan\": \"Asia\"}\n",
    "\n",
    "final_result_sorted['region'] = final_result_sorted['country'].map(country_regions)\n",
    "\n",
    "region_palette = {\n",
    "    'Europe': 'yellowgreen',\n",
    "    'Asia': 'orangered',\n",
    "    'Africa': 'darkseagreen',\n",
    "    'North America': 'turquoise',\n",
    "    'South America': 'paleturquoise'\n",
    "}\n",
    "\n",
    "final_result_sorted['region_color'] = final_result_sorted['region'].map(region_palette)\n",
    "final_result_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Heatmap for Similarity\n",
    "- This is plotted for each country (across all categories)\n",
    "- Similarity = 1 - JSD\n",
    "- Origin: Mean Similarity across all countries\n",
    "- Distance Per Country = Similarity Score Per Country - Origin (Mean Similarity Score) \n",
    "- Higher Similarity Distance = Closer to Human Distriubtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate the mean similarity value\n",
    "origin = final_result_sorted['similarity'].mean()\n",
    "\n",
    "# Sort data based on similarity\n",
    "final_result_sorted = final_result_sorted.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "# Calculate deviation from the mean (center the bars at the mean similarity)\n",
    "final_result_sorted['similarity_centered'] = final_result_sorted['similarity'] - origin\n",
    "\n",
    "mapped_dict = dict(zip(final_result_sorted['country'], final_result_sorted['income_color']))\n",
    "\n",
    "# Plot vertical bar chart centered on the mean similarity\n",
    "bars = sns.barplot(\n",
    "    x='country',\n",
    "    y='similarity_centered',\n",
    "    data=final_result_sorted,\n",
    "    palette=mapped_dict\n",
    ")\n",
    "\n",
    "# Add a horizontal line for the centered mean (origin)\n",
    "# plt.axhline(0, color='blue', linestyle='--', label=f'Mean similarity = {origin:.2f}')\n",
    "\n",
    "# Set the y-axis limits to highlight the range\n",
    "plt.ylim(-0.085, 0.075)\n",
    "\n",
    "# Remove x-axis labels\n",
    "plt.xticks([])\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Similarity Distance Score - Income Wise')\n",
    "plt.xlabel('')  # Optionally, remove x-axis label as well\n",
    "plt.title('Similarity Distance Score For Each Country')\n",
    "\n",
    "# Display legend about color mapping. Top right corner. Label: income, color: color\n",
    "# Display in a bo\n",
    "# Create custom legend handles\n",
    "legend_handles = [plt.Line2D([0], [0], color=color, lw=4) for color in category_palette.values()]\n",
    "\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    labels=[f'{key}' for key, value in category_palette.items()],\n",
    "    title='Income',\n",
    "    loc='upper right',\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Annotate bars with the country names\n",
    "for bar, country in zip(bars.patches, final_result_sorted['country']):\n",
    "    height = bar.get_height()\n",
    "    # Place text slightly above the bar\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + (0.001 if height >= 0 else -0.001),  # Adjust position based on height\n",
    "        country,\n",
    "        ha='center',\n",
    "        va='bottom' if height >= 0 else 'top',  # Adjust alignment based on direction\n",
    "        fontsize=8,\n",
    "        rotation=90  # Rotate text for better readability\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of Similarity Heatmap for each country (across all categories) - Region Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Calculate the mean similarity value\n",
    "origin = final_result_sorted['similarity'].mean()\n",
    "\n",
    "# Sort data based on similarity\n",
    "final_result_sorted = final_result_sorted.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "# Calculate deviation from the mean (center the bars at the mean similarity)\n",
    "final_result_sorted['similarity_centered'] = final_result_sorted['similarity'] - origin\n",
    "\n",
    "mapped_dict = dict(zip(final_result_sorted['country'], final_result_sorted['region_color']))\n",
    "\n",
    "# Plot vertical bar chart centered on the mean similarity\n",
    "bars = sns.barplot(\n",
    "    x='country',\n",
    "    y='similarity_centered',\n",
    "    data=final_result_sorted,\n",
    "    palette=mapped_dict\n",
    ")\n",
    "\n",
    "# Add a horizontal line for the centered mean (origin)\n",
    "# plt.axhline(0, color='blue', linestyle='--', label=f'Mean similarity = {origin:.2f}')\n",
    "\n",
    "# Set the y-axis limits to highlight the range\n",
    "plt.ylim(-0.085, 0.075)\n",
    "\n",
    "# Remove x-axis labels\n",
    "plt.xticks([])\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Similarity Distance Score: Region Wise')\n",
    "plt.xlabel('')  # Optionally, remove x-axis label as well\n",
    "plt.title('Similarity Distance Score For Each Country')\n",
    "\n",
    "# Display legend with color mapping. Top right corner. Label: region, color: color\n",
    "# Display in a box\n",
    "# Create custom legend handles\n",
    "legend_handles = [plt.Line2D([0], [0], color=color, lw=4) for color in region_palette.values()]\n",
    "\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    labels=[f'{key}' for key, value in region_palette.items()],\n",
    "    title='Region',\n",
    "    loc='upper right',\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Annotate bars with the country names\n",
    "for bar, country in zip(bars.patches, final_result_sorted['country']):\n",
    "    height = bar.get_height()\n",
    "    # Place text slightly above the bar\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + (0.001 if height >= 0 else -0.001),  # Adjust position based on height\n",
    "        country,\n",
    "        ha='center',\n",
    "        va='bottom' if height >= 0 else 'top',  # Adjust alignment based on direction\n",
    "        fontsize=8,\n",
    "        rotation=90  # Rotate text for better readability\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot For Normalized Similarity Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Normalzed Similarity Heatmap for each country\n",
    "\n",
    "# import numpy as np\n",
    "sim_values = final_result_sorted['similarity'].to_list()\n",
    "min_sim = np.min(sim_values)\n",
    "max_sim = np.max(sim_values)\n",
    "rescaled_sim = [(sim - min_sim) / (max_sim - min_sim) for sim in sim_values]\n",
    "\n",
    "final_result_sorted['rescaled_similarity'] = rescaled_sim\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# Sort data based on rescaled imilarity\n",
    "final_result_sorted = final_result_sorted.sort_values(by='rescaled_similarity', ascending=False)\n",
    "\n",
    "# Map colors based on the category_group\n",
    "# mapped_palette = final_result_sorted['country_group'].map(final_result_sorted['income_color'])\n",
    "mapped_dict = dict(zip(final_result_sorted['country'], final_result_sorted['income_color']))\n",
    "\n",
    "# Plot vertical bar chart centered on the mean similarity\n",
    "bars = sns.barplot(\n",
    "    x='country',\n",
    "    y='rescaled_similarity',\n",
    "    data=final_result_sorted,\n",
    "    palette=mapped_dict\n",
    ")\n",
    "\n",
    "# Add a horizontal line for the centered mean (origin)\n",
    "plt.axhline(0.5, color='blue', linestyle='--', label=f'Normalized Similarity')\n",
    "\n",
    "# Set the y-axis limits to highlight the range\n",
    "plt.ylim(0, 1.2)\n",
    "\n",
    "# Remove x-axis labels\n",
    "plt.xticks([])\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Normalized Similarity Distance Score - Income Wise')\n",
    "plt.xlabel('')  # Optionally, remove x-axis label as well\n",
    "plt.title('Normalized Similarity Distance Score For Each Country')\n",
    "\n",
    "# Display legend about color mapping. Top right corner. Label: income, color: color\n",
    "# Display in a bo\n",
    "# Create custom legend handles\n",
    "legend_handles = [plt.Line2D([0], [0], color=color, lw=4) for color in category_palette.values()]\n",
    "\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    labels=[f'{key}' for key, value in category_palette.items()],\n",
    "    title='Income',\n",
    "    loc='upper right',\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Annotate bars with the country names\n",
    "for bar, country in zip(bars.patches, final_result_sorted['country']):\n",
    "    height = bar.get_height()\n",
    "    # Place text slightly above the bar\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + (0.001 if height >= 0 else -0.001),  # Adjust position based on height\n",
    "        country,\n",
    "        ha='center',\n",
    "        va='bottom' if height >= 0 else 'top',  # Adjust alignment based on direction\n",
    "        fontsize=8,\n",
    "        rotation=90  # Rotate text for better readability\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for Normalized Similarity Distance region wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot Normalzed Similarity Heatmap for each country\n",
    "\n",
    "# import numpy as np\n",
    "sim_values = final_result_sorted['similarity'].to_list()\n",
    "min_sim = np.min(sim_values)\n",
    "max_sim = np.max(sim_values)\n",
    "rescaled_sim = [(sim - min_sim) / (max_sim - min_sim) for sim in sim_values]\n",
    "\n",
    "final_result_sorted['rescaled_similarity'] = rescaled_sim\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "\n",
    "# Sort data based on rescaled imilarity\n",
    "final_result_sorted = final_result_sorted.sort_values(by='rescaled_similarity', ascending=False)\n",
    "\n",
    "# Map colors based on the category_group\n",
    "# mapped_palette = final_result_sorted['country_group'].map(final_result_sorted['region_color'])\n",
    "mapped_dict = dict(zip(final_result_sorted['country'], final_result_sorted['region_color']))\n",
    "\n",
    "# Plot vertical bar chart centered on the mean similarity\n",
    "bars = sns.barplot(\n",
    "    x='country',\n",
    "    y='rescaled_similarity',\n",
    "    data=final_result_sorted,\n",
    "    palette=mapped_dict\n",
    ")\n",
    "\n",
    "# Add a horizontal line for the centered mean (origin)\n",
    "plt.axhline(0.5, color='blue', linestyle='--', label=f'Normalized Similarity: 0.5')\n",
    "\n",
    "# Set the y-axis limits to highlight the range\n",
    "plt.ylim(0, 1.2)\n",
    "\n",
    "# Remove x-axis labels\n",
    "plt.xticks([])\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel('Normalized Similarity Distance Score - Region Wise')\n",
    "plt.xlabel('')  # Optionally, remove x-axis label as well\n",
    "plt.title('Normalized Similarity Distance Score For Each Country')\n",
    "\n",
    "# Display legend\n",
    "# Display legend about color mapping. Top right corner. Label: region, color: color\n",
    "# Display in a bo\n",
    "# Create custom legend handles\n",
    "legend_handles = [plt.Line2D([0], [0], color=color, lw=4) for color in region_palette.values()]\n",
    "\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    labels=[f'{key}' for key, value in region_palette.items()],\n",
    "    title='Region',\n",
    "    loc='upper right',\n",
    "    fontsize=8\n",
    ")\n",
    "\n",
    "# Annotate bars with the country names\n",
    "for bar, country in zip(bars.patches, final_result_sorted['country']):\n",
    "    height = bar.get_height()\n",
    "    # Place text slightly above the bar\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        height + (0.001 if height >= 0 else -0.001),  # Adjust position based on height\n",
    "        country,\n",
    "        ha='center',\n",
    "        va='bottom' if height >= 0 else 'top',  # Adjust alignment based on direction\n",
    "        fontsize=8,\n",
    "        rotation=90  # Rotate text for better readability\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer JSD, SIM Per Category Per Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for f in files:\n",
    "    data = pd.read_csv(os.path.join(directory, f))\n",
    "\n",
    "    # Add category column to the DataFrame\n",
    "    data['category'] = data['image_path'].apply(lambda x: x.split('/')[-1].split('.')[0].split('_')[1:-2])\n",
    "    data['category'] = data['category'].apply(lambda x: '_'.join(x))\n",
    "\n",
    "    # Example gt and pred (list of lists)\n",
    "    gt = [ast.literal_eval(x) for x in data['selection_answers'].tolist()]\n",
    "    pred = [ast.literal_eval(x) for x in data['prob_percent_values'].tolist()]\n",
    "\n",
    "    # Original DataFrame, retaining all columns from `data`\n",
    "    df = data.copy()\n",
    "\n",
    "    # Keep track of matching indices\n",
    "    matching_indices = [i for i, (g, p) in enumerate(zip(gt, pred)) if len(g) == len(p)]\n",
    "\n",
    "    # Filter rows where len(g) == len(p)\n",
    "    filtered_gt_pred = [(g, p) for g, p in zip(gt, pred) if len(g) == len(p)]\n",
    "\n",
    "    # If there are any matching rows\n",
    "    if filtered_gt_pred:\n",
    "        gt_filtered, pred_filtered = zip(*filtered_gt_pred)\n",
    "\n",
    "        # Calculate JSD\n",
    "        jsd = [distance.jensenshannon(g, p) for g, p in zip(gt_filtered, pred_filtered)]\n",
    "        similarity = [1 - value for value in jsd]\n",
    "\n",
    "        # Add JSD and similarity values back to the DataFrame\n",
    "        df.loc[matching_indices, 'jsd'] = jsd\n",
    "        df.loc[matching_indices, 'similarity'] = similarity\n",
    "    else:\n",
    "        df['jsd'] = None  # or handle the case accordingly\n",
    "        df['similarity'] = None\n",
    "\n",
    "    # Set JSD and similarity to NaN or a placeholder for rows that were filtered out\n",
    "    df['jsd'] = pd.to_numeric(df['jsd'], errors='coerce')\n",
    "    df['similarity'] = pd.to_numeric(df['similarity'], errors='coerce')\n",
    "\n",
    "    # Calculate mean of jsd and similarity per country and per category\n",
    "    mean_per_country_category = df.groupby(['country', 'category'])[['jsd', 'similarity']].mean().reset_index()\n",
    "\n",
    "    # Append results to list\n",
    "    results.append(mean_per_country_category)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_result = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_sorted = final_result.set_index('country').loc[country_order].reset_index()\n",
    "# Create a new column in the DataFrame for country category\n",
    "final_result_sorted['category_group'] = final_result_sorted['country'].map(country_mapping)\n",
    "final_result_sorted['category_color'] = final_result_sorted['category_group'].map(category_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_sorted['region'] = final_result_sorted['country'].map(country_regions)\n",
    "final_result_sorted['region_color'] = final_result_sorted['region'].map(region_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Heatmap for Similarity for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_dir = \"income_category\"\n",
    "if not os.path.exists(income_dir):\n",
    "    os.makedirs(income_dir)\n",
    "\n",
    "# Plot similarity per category for all countries and save each plot\n",
    "categories = final_result_sorted['category'].unique()\n",
    "\n",
    "for category in categories:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Filter data for the current category (include all countries under this category)\n",
    "    category_data = final_result_sorted[final_result_sorted['category'] == category]\n",
    "\n",
    "    # # Drop NaNs in the similarity column\n",
    "    # category_data = category_data.dropna(subset=['similarity'])\n",
    "\n",
    "    # Sort data based on similarity for better visualization\n",
    "    category_data = category_data.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "    # Calculate the mean similarity value for the current category across all countries\n",
    "    origin = category_data['similarity'].mean()\n",
    "    # print(f\"origin: {origin}\")\n",
    "\n",
    "    # Calculate deviation from the mean (center the bars at the mean similarity)\n",
    "    category_data['similarity_centered'] = category_data['similarity'] - origin\n",
    "\n",
    "    # Map colors based on the category_group\n",
    "    mapped_palette = category_data['category_group'].map(category_palette)\n",
    "\n",
    "    # Ensure no missing values in the mapped palette\n",
    "    if mapped_palette.isnull().any():\n",
    "        print(\"Warning: Some category groups are not mapped to colors.\")\n",
    "        print(category_data[mapped_palette.isnull()])\n",
    "\n",
    "    mapped_dict = dict(zip(category_data['country'], mapped_palette))\n",
    "    # Plot vertical bar chart centered on the mean similarity\n",
    "    bars = sns.barplot(\n",
    "        x='country',\n",
    "        y='similarity_centered',\n",
    "        data=category_data,\n",
    "        palette=mapped_dict\n",
    "    )\n",
    "\n",
    "    # Add a horizontal line for the centered mean (origin)\n",
    "    plt.axhline(0, color='blue', linestyle='--', label=f'Mean similarity = {origin:.2f}')\n",
    "\n",
    "    # Set the y-axis limits to highlight the range\n",
    "    plt.ylim(-0.065, 0.065)\n",
    "\n",
    "    # Remove x-axis labels\n",
    "    plt.xticks([])\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.ylabel('Similarity Deviation from Mean')\n",
    "    plt.xlabel('Country')\n",
    "    plt.title(f'Countries by Deviation in Similarity from the Mean for Category: {category}')\n",
    "\n",
    "    # Display legend\n",
    "    # Display legend about color mapping. Top right corner. Label: income, color: color\n",
    "    # Display in a box\n",
    "    # Create custom legend handles\n",
    "    legend_handles = [plt.Line2D([0], [0], color=color, lw=4) for color in category_palette.values()]\n",
    "\n",
    "    plt.legend(\n",
    "        handles=legend_handles,\n",
    "        labels=[f'{key}' for key, value in category_palette.items()],\n",
    "        title='Income',\n",
    "        loc='upper right',\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "    # Annotate bars with the country names\n",
    "    for bar, country in zip(bars.patches, category_data['country']):\n",
    "        height = bar.get_height()\n",
    "        # Place text slightly above the bar\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + (0.01 if height >= 0 else -0.01),  # Adjust position based on height\n",
    "            country,\n",
    "            ha='center',\n",
    "            va='bottom' if height >= 0 else 'top',  # Adjust alignment based on direction\n",
    "            fontsize=6,\n",
    "            rotation=90  # Rotate text for better readability\n",
    "        )\n",
    "    # Save the plot as a file\n",
    "    plt.savefig(f'{income_dir}/{category}.png', bbox_inches='tight')\n",
    "    print(f\"Saved category: {category}\")\n",
    "\n",
    "    # Close the plot to free memory\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of Similarity Heatmap for each category (across all countries) - Region Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dir = \"regions_categories\"\n",
    "if not os.path.exists(region_dir):\n",
    "    os.makedirs(region_dir)\n",
    "\n",
    "# Plot similarity per category for all countries and save each plot\n",
    "for category in categories:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Filter data for the current category (include all countries under this category)\n",
    "    category_data = final_result_sorted[final_result_sorted['category'] == category]\n",
    "\n",
    "    # # Drop NaNs in the similarity column\n",
    "    # category_data = category_data.dropna(subset=['similarity'])\n",
    "\n",
    "    # Sort data based on similarity for better visualization\n",
    "    category_data = category_data.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "    # Calculate the mean similarity value for the current category across all countries\n",
    "    origin = category_data['similarity'].mean()\n",
    "    # print(f\"origin: {origin}\")\n",
    "\n",
    "    # Calculate deviation from the mean (center the bars at the mean similarity)\n",
    "    category_data['similarity_centered'] = category_data['similarity'] - origin\n",
    "\n",
    "    # Map colors based on the category_group\n",
    "    mapped_palette = category_data['region_color']\n",
    "\n",
    "    # Ensure no missing values in the mapped palette\n",
    "    if mapped_palette.isnull().any():\n",
    "        print(\"Warning: Some category groups are not mapped to colors.\")\n",
    "        print(category_data[mapped_palette.isnull()])\n",
    "\n",
    "    mapped_dict = dict(zip(category_data['country'], mapped_palette))\n",
    "    # Plot vertical bar chart centered on the mean similarity\n",
    "    bars = sns.barplot(\n",
    "        x='country',\n",
    "        y='similarity_centered',\n",
    "        data=category_data,\n",
    "        palette=mapped_dict\n",
    "    )\n",
    "\n",
    "    # Add a horizontal line for the centered mean (origin)\n",
    "    # plt.axhline(0, color='blue', linestyle='--', label=f'Mean similarity = {origin:.2f}')\n",
    "\n",
    "    # Set the y-axis limits to highlight the range\n",
    "    plt.ylim(-0.065, 0.065)\n",
    "\n",
    "    # Remove x-axis labels\n",
    "    plt.xticks([])\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.ylabel('Similarity Deviation from Mean')\n",
    "    plt.xlabel('Country')\n",
    "    plt.title(f'Countries by Deviation in Similarity from the Mean for Category: {category}')\n",
    "\n",
    "    # Display legend\n",
    "    # Display legend about color mapping. Top right corner. Label: region, color: color\n",
    "    # Display in a box\n",
    "    # Create custom legend handles\n",
    "    legend_handles = [plt.Line2D([0], [0], color=color, lw=4) for color in region_palette.values()]\n",
    "\n",
    "    plt.legend(\n",
    "        handles=legend_handles,\n",
    "        labels=[f'{key}' for key, value in region_palette.items()],\n",
    "        title='Region',\n",
    "        loc='upper right',\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "    # Annotate bars with the country names\n",
    "    for bar, country in zip(bars.patches, category_data['country']):\n",
    "        height = bar.get_height()\n",
    "        # Place text slightly above the bar\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            height + (0.01 if height >= 0 else -0.01),  # Adjust position based on height\n",
    "            country,\n",
    "            ha='center',\n",
    "            va='bottom' if height >= 0 else 'top',  # Adjust alignment based on direction\n",
    "            fontsize=6,\n",
    "            rotation=90  # Rotate text for better readability  \n",
    "        )\n",
    "\n",
    "    # Save the plot as a file\n",
    "    plt.savefig(f'{region_dir}/similarity_per_category_{category}.png', bbox_inches='tight')\n",
    "    print(f\"Saved category: {category}\")\n",
    "\n",
    "    # Close the plot to free memory\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "culture-values",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
